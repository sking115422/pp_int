{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/int_venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import glob\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.structures.instances import Instances\n",
    "from multiprocessing import Process, Manager\n",
    "import gc\n",
    "from PIL import Image, ImageDraw, ImageFont\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PATHS\n",
    "# Do not use directory with negatives\n",
    "in_dir = \"/mnt/lts/nis_lab_research/data/coco_files/og/test/ft_test1_c10\"\n",
    "# in_dir = \"/mnt/lts/nis_lab_research/data/coco_files/og/test/ft_test1\"\n",
    "res_out_dir = \"./res_out_dir\"\n",
    "vis_out_dir = \"./res_out_dir/vis\"\n",
    "# cat_path = \"/mnt/lts/nis_lab_research/data/elem_cat/cat_neg_27.json\"\n",
    "cat_path = \"/mnt/lts/nis_lab_research/data/elem_cat/cat_neg_10.json\"\n",
    "master_url_dict_path = '/mnt/lts/nis_lab_research/data/top-1m/top-1m-mapping.json'\n",
    "\n",
    "\n",
    "# OBJECT DETECTOR MODELS\n",
    "# # 2 OD\n",
    "od_paths = [\n",
    "    (\"/mnt/lts/nis_lab_research/data/coco_files/agg/class_2_rem/out/far_shah_b1-b5_b8_train_c0/model_final.pth\", 0.50), # small\n",
    "    (\"/mnt/lts/nis_lab_research/data/coco_files/agg/class_2_rem/out/far_shah_b1-b5_b8_train_c1/model_final.pth\", 0.75)  # large\n",
    "]\n",
    "\n",
    "# # 10 OD\n",
    "# od_paths = [\n",
    "#     (\"/mnt/lts/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c0/model_final.pth\", .75),\n",
    "#     (\"/mnt/lts/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c1/model_final.pth\", .75),\n",
    "#     (\"/mnt/lts/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c2/model_final.pth\", .75),\n",
    "#     (\"/mnt/lts/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c3/model_final.pth\", .75),\n",
    "#     (\"/mnt/lts/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c4/model_final.pth\", .75),\n",
    "#     (\"/mnt/lts/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c5/model_final.pth\", .75),\n",
    "#     (\"/mnt/lts/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c6/model_final.pth\", .75),\n",
    "#     (\"/mnt/lts/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c7/model_final.pth\", .75),\n",
    "#     (\"/mnt/lts/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c8/model_final.pth\", .75),\n",
    "#     (\"/mnt/lts/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c9/model_final.pth\", .75)\n",
    "# ]\n",
    "\n",
    "# CLASSIFIER MODEL\n",
    "# # 10 Class Agg + Neg\n",
    "# class_path = \"/mnt/lts/nis_lab_research/data/class_data/pth/far_shah_b1-b5_b8_train_c10_neg/model_final.pth\"\n",
    "class_path = \"/mnt/lts/nis_lab_research/data/class_data/pth/full_train_neg_c10/model_final.pth\"\n",
    "# 27 Class + Neg\n",
    "# class_path = \"/mnt/lts/nis_lab_research/data/class_data/pth/far_shah_b1-b5_b8_train_neg/model_final.pth\"\n",
    "\n",
    "# ADJUSTABLES\n",
    "bg_color = \"white\"\n",
    "# Possibly adjust padding to fixed value in the future\n",
    "padding = 0.15\n",
    "border = 0\n",
    "\n",
    "# Common element that are nested will be denested by default\n",
    "denest = True\n",
    "denest_thold = 0.20\n",
    "\n",
    "keep_clickable_elems_only = False\n",
    "\n",
    "# If True negatively identified cases will be removed before calulating metrics\n",
    "remove_neg = True\n",
    "\n",
    "\n",
    "iou_thold = .5\n",
    "neg_class_name = \"Random\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting CUDA devices as visible\n",
    "cuda_devices = \"0,1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CUDA devices:\n",
      "  0: Tesla P100-PCIE-16GB\n",
      "  1: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "available_devices = [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]\n",
    "print(\"Available CUDA devices:\")\n",
    "for i, device_name in enumerate(available_devices):\n",
    "    print(f\"  {i}: {device_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soi(str1, start_char, end_char):\n",
    "    str1 = str(str1)\n",
    "    offst = len(start_char)\n",
    "    ind1 = str1.find(start_char)\n",
    "    ind2 = str1.find(end_char)\n",
    "    s_str = str1[ind1+offst:ind2]\n",
    "    return s_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bbox_xywh(b):\n",
    "    x1, y1, x2, y2 = b\n",
    "    x = x1\n",
    "    y = y1\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    return [x, y, w, h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createDataDict (fn, outputs):\n",
    "    img_shape = list(outputs[\"instances\"].image_size)\n",
    "    img_h = int(img_shape[0])\n",
    "    img_w = int(img_shape[1])\n",
    "    ann_list = []\n",
    "\n",
    "    class_list = get_soi(outputs[\"instances\"].pred_classes, \"[\", \"]\").split(\",\")\n",
    "    \n",
    "    if class_list[0] != \"\":\n",
    "\n",
    "        class_list_new = []\n",
    "        for each in class_list:\n",
    "            if each.strip().isdigit():\n",
    "                class_list_new.append(int(each.strip()))\n",
    "            else:\n",
    "                print(f\"Invalid class ID: {each}\")\n",
    "\n",
    "        bbox_list = get_soi(outputs[\"instances\"].pred_boxes, \"[[\", \"]]\").split(\"]\")\n",
    "        bbox_list_new = []\n",
    "        for each in bbox_list:\n",
    "            bbox = re.sub(\"['[,\\n]\", \"\", each).split(\" \")\n",
    "            bbox_new = []\n",
    "            for item in bbox:\n",
    "                if item != \"\":\n",
    "                    bbox_new.append(float(item))\n",
    "            bbox_new = convert_bbox_xywh(bbox_new)\n",
    "            bbox_list_new.append(bbox_new)\n",
    "\n",
    "        for i in range(0, len(class_list)):\n",
    "            # og was \"bbox_mode\": \"<BoxMode.XYWH_ABS: 1>\"\n",
    "            ann_list.append({\"iscrowd\": 0, \"bbox\": bbox_list_new[i], \"category_id\": class_list_new[i], \"bbox_mode\": 0})\n",
    "    \n",
    "    data_dict = {\n",
    "        \"file_name\": fn,\n",
    "        \"height\": img_h,\n",
    "        \"width\": img_w, \n",
    "        \"annotations\": ann_list\n",
    "    }\n",
    " \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(file_path, bounding_box, padding):\n",
    "    \n",
    "    with Image.open(file_path) as img:\n",
    "        \n",
    "        x_min, y_min, width, height = bounding_box\n",
    "\n",
    "        # Calculate padding in pixels\n",
    "        pad_width = int(width * padding)\n",
    "        pad_height = int(height * padding)\n",
    "\n",
    "        # Adjust the bounding box with padding\n",
    "        x_min = max(x_min - pad_width, 0)\n",
    "        y_min = max(y_min - pad_height, 0)\n",
    "        x1 = min(x_min + width + 2 * pad_width, img.width)\n",
    "        y1 = min(y_min + height + 2 * pad_height, img.height)\n",
    "        \n",
    "        cropped_img = img.crop((x_min, y_min, x1, y1))\n",
    "        \n",
    "        return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paste_to_bg(image, background_color, bg_width, bg_height):\n",
    "    \n",
    "    # Create a new image with the specified background color and dimensions\n",
    "    background = Image.new('RGB', (bg_width, bg_height), background_color)\n",
    "\n",
    "    # Calculate the position to paste the image so it's centered\n",
    "    x = (bg_width - image.width) // 2\n",
    "    y = (bg_height - image.height) // 2\n",
    "\n",
    "    # Paste the image onto the background\n",
    "    background.paste(image, (x, y), image if image.mode == 'RGBA' else None)\n",
    "\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_ar_lock(img, target_size):\n",
    "\n",
    "    original_width, original_height = img.size\n",
    "    target_width, target_height = target_size\n",
    "\n",
    "    # Calculate scaling factor\n",
    "    scaling_factor = min(target_width / original_width, target_height / original_height)\n",
    "\n",
    "    # Calculate new dimensions\n",
    "    new_width = max(int(original_width * scaling_factor), 1)\n",
    "    new_height = max(int(original_height * scaling_factor), 1)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = img.resize((new_width, new_height))\n",
    "\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rand_str(length):\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    random_string = ''.join(random.choice(characters) for i in range(length))\n",
    "    return random_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img_fp, bbox_list, padding, bg_color, border):\n",
    "    \n",
    "    # Create an empty list to store processed images\n",
    "    processed_images = []\n",
    "\n",
    "    for j, bbox in enumerate(bbox_list):\n",
    "\n",
    "        try:\n",
    "            elem_img = crop_image(img_fp, bbox, padding)\n",
    "            e_w = elem_img.size[0]\n",
    "            e_h = elem_img.size[1]\n",
    "\n",
    "            if e_w < e_h:\n",
    "                elem_img = paste_to_bg(elem_img, bg_color, e_h + border, e_h + border)\n",
    "            elif e_w > e_h:\n",
    "                elem_img = paste_to_bg(elem_img, bg_color, e_w + border, e_w + border)\n",
    "                \n",
    "            # elem_img = transform(elem_img)\n",
    "            processed_images.append(elem_img)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(img_fp)\n",
    "            print(e)\n",
    "\n",
    "    # Return the list of processed images\n",
    "    return processed_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(image_path, bbox_list, label_list, output_path, color = 'red', thickness=2):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Load a font\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    # Draw bounding boxes and labels\n",
    "    for bbox, label in zip(bbox_list, label_list):\n",
    "        x, y, w, h = bbox\n",
    "        draw.rectangle([x, y, x+w, y+h], outline=color, width = 2)\n",
    "        draw.text((x, y), label, fill=color, font=font)\n",
    "\n",
    "    # Save the new image\n",
    "    image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes_in_mem(image, bbox_list, label_list, color='red', thickness=2):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    for bbox, label in zip(bbox_list, label_list):\n",
    "        x, y, w, h = bbox\n",
    "        draw.rectangle([x, y, x + w, y + h], outline=color, width=thickness)\n",
    "        draw.text((x, y), label, fill=color, font=font)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_outputs(outputs):\n",
    "    l = []\n",
    "    for out in outputs:\n",
    "        l.append(out[\"instances\"])\n",
    "    new = Instances.cat(l)\n",
    "    return {\"instances\": new}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_all_but_first_part(s):\n",
    "    parts = s.split('-')\n",
    "    if len(parts) > 1:\n",
    "        return '-'.join(parts[1:])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(res_out_dir):\n",
    "    shutil.rmtree(res_out_dir)\n",
    "os.makedirs(vis_out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_list = [os.path.join(in_dir, \"images\", img_path) for img_path in sorted(os.listdir(os.path.join(in_dir, \"images\")))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/22 18:47:01 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /mnt/nis_lab_research/data/coco_files/agg/class_2_rem/out/far_shah_b1-b5_b8_train_c0/model_final.pth ...\n",
      "\u001b[32m[07/22 18:47:03 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /mnt/nis_lab_research/data/coco_files/agg/class_2_rem/out/far_shah_b1-b5_b8_train_c1/model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "obj_det_pred_list = []\n",
    "\n",
    "for od in od_paths:\n",
    "    \n",
    "    setup_logger()\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "    # cfg.MODEL.WEIGHTS = os.path.join(\"/home/dtron2_user/ls_dtron2_full/model/output\", \"model_final.pth\")\n",
    "    cfg.MODEL.WEIGHTS = od[0]\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = od[1] \n",
    "    obj_det_pred = DefaultPredictor(cfg)\n",
    "    obj_det_pred_list.append(obj_det_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=11, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = torch.load(class_path)\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cat_path, 'r') as f:\n",
    "    cats = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_class_id = \"\"\n",
    "\n",
    "for key, value in cats.items():\n",
    "    if value == neg_class_name:\n",
    "        neg_class_id = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(master_url_dict_path) as f:\n",
    "    master_url_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clickable_elements(domains):\n",
    "    obj_list = []\n",
    "\n",
    "    for dom in domains:\n",
    "        print(dom)\n",
    "        url = f'https://{dom}'\n",
    "        cmd = ['xvfb-run', 'node', '../../get_clickable_elems/get_clickable_elems.js', url]\n",
    "\n",
    "        try:\n",
    "            result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
    "            print(result.stdout)  # Print the standard output from the command\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error executing command: {e}\")\n",
    "            print(f\"Command output: {e.output}\")\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        json_path = os.path.join('./data', f'{dom}.json')\n",
    "        if os.path.exists(json_path):\n",
    "            with open(json_path) as f:\n",
    "                jobj = json.load(f)\n",
    "\n",
    "            obj_list.append(jobj)\n",
    "\n",
    "    return obj_list if obj_list else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(boxA, boxB):\n",
    "    # Convert from [x, y, w, h] to [x1, y1, x2, y2]\n",
    "    x1A, y1A, x2A, y2A = boxA[0], boxA[1], boxA[0] + boxA[2], boxA[1] + boxA[3]\n",
    "    x1B, y1B, x2B, y2B = boxB[0], boxB[1], boxB[0] + boxB[2], boxB[1] + boxB[3]\n",
    "    \n",
    "    # Determine the coordinates of the intersection rectangle\n",
    "    xA = max(x1A, x1B)\n",
    "    yA = max(y1A, y1B)\n",
    "    xB = min(x2A, x2B)\n",
    "    yB = min(y2A, y2B)\n",
    "    \n",
    "    # Compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    \n",
    "    # Compute the area of both the prediction and true bounding boxes\n",
    "    boxAArea = (x2A - x1A) * (y2A - y1A)\n",
    "    boxBArea = (x2B - x1B) * (y2B - y1B)\n",
    "    \n",
    "    # Compute the area of union\n",
    "    unionArea = boxAArea + boxBArea - interArea\n",
    "    \n",
    "    # Compute the Intersection over Union by dividing the intersection area by the union area\n",
    "    iou = interArea / unionArea\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_contains(bbox1, bbox2):\n",
    "    return (bbox1[0] <= bbox2[0] and\n",
    "            bbox1[1] <= bbox2[1] and\n",
    "            bbox1[0] + bbox1[2] >= bbox2[0] + bbox2[2] and\n",
    "            bbox1[1] + bbox1[3] >= bbox2[1] + bbox2[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_clickable_elem_ind_list(img_path, pred_bbox_list):\n",
    "\n",
    "    # Extract the key from the image path\n",
    "    key = keep_all_but_first_part(img_path.split('/')[-1])[:-7]\n",
    "\n",
    "    # Get the domain from the master_url_dict using the key\n",
    "    domain = master_url_dict.get(key)\n",
    "    if not domain:\n",
    "        raise ValueError(f\"Key {key} not found in master_url_dict\")\n",
    "\n",
    "    # Get clickable elements for the domain\n",
    "    ces = get_clickable_elements([domain])\n",
    "\n",
    "    if ces is None:\n",
    "        return None, None\n",
    "    else:\n",
    "        ces_obj = ces[0]\n",
    "\n",
    "        # Build list of clickable bounding boxes\n",
    "        clickable_bbox_list = [[ce['x'], ce['y'], ce['width'], ce['height']] for ce in ces_obj]\n",
    "\n",
    "        # List to hold non-clickable element indices\n",
    "        non_clickable_ind_list = []\n",
    "\n",
    "        # Check each predicted bounding box against clickable bounding boxes\n",
    "        for i, p_bbox in enumerate(pred_bbox_list):\n",
    "            is_non_clickable = True\n",
    "            for ces in ces_obj:\n",
    "                ces_bbox = [ces['x'], ces['y'], ces['width'], ces['height']]\n",
    "                iou_score = calculate_iou(p_bbox, ces_bbox)\n",
    "                # if overlap between predicted element and clickable element is greater that threshold\n",
    "                # or if one is contained in the other. It will be kept as clickable predicted element.\n",
    "                if (iou_score >= 0.5 or\n",
    "                    bbox_contains(p_bbox, ces_bbox) or\n",
    "                    bbox_contains(ces_bbox, p_bbox)):\n",
    "                    is_non_clickable = False\n",
    "                    break\n",
    "            if is_non_clickable:\n",
    "                non_clickable_ind_list.append(i)\n",
    "\n",
    "        return non_clickable_ind_list, clickable_bbox_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_search_dict(dictionary, target_value):\n",
    "    for key, value in dictionary.items():\n",
    "        if value == target_value:\n",
    "            return key\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nested_bboxes(bboxes, iou_threshold=0.20):\n",
    "    indices_to_remove = []\n",
    "    \n",
    "    # Create a list of indices\n",
    "    remaining_indices = list(range(len(bboxes)))\n",
    "    \n",
    "    while remaining_indices:\n",
    "        # Get the index and corresponding box of the first element in remaining_indices\n",
    "        current_index = remaining_indices.pop(0)\n",
    "        current_box = bboxes[current_index]\n",
    "        \n",
    "        # List to hold indices of boxes that do not overlap significantly\n",
    "        non_overlapping_indices = []\n",
    "        \n",
    "        for other_index in remaining_indices:\n",
    "            other_box = bboxes[other_index]\n",
    "            iou = calculate_iou(current_box, other_box)\n",
    "            \n",
    "            # if box contains another box that is large enough keep outter box\n",
    "            if (iou > iou_threshold and (bbox_contains(current_box, other_box) or bbox_contains(other_box, current_box))):\n",
    "                if (current_box[2] * current_box[3]) >= (other_box[2] * other_box[3]):\n",
    "                    indices_to_remove.append(other_index)\n",
    "                else:\n",
    "                    indices_to_remove.append(current_index)\n",
    "                    current_box = other_box\n",
    "                    current_index = other_index\n",
    "            # if too much overlap between boxes keep larger box\n",
    "            elif iou > iou_threshold:\n",
    "                if (current_box[2] * current_box[3]) >= (other_box[2] * other_box[3]):\n",
    "                    indices_to_remove.append(other_index)\n",
    "                else:\n",
    "                    indices_to_remove.append(current_index)\n",
    "                    current_box = other_box\n",
    "                    current_index = other_index\n",
    "            else:\n",
    "                non_overlapping_indices.append(other_index)\n",
    "        \n",
    "        # Update the list of remaining indices to check\n",
    "        remaining_indices = non_overlapping_indices\n",
    "    \n",
    "    return sorted(indices_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/int_venv/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################################################################################\n",
      "0 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/0UnHYuFgKVpkj5fl-climbkalymnos_ss.png\n",
      "predicted number: 28\n",
      "denested number: 28\n",
      "cleaned number after removing negative classes: 26\n",
      "###############################################################################################\n",
      "1 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/0XQJNLHix7U3ywoz-trollalley_ss.png\n",
      "predicted number: 43\n",
      "denested number: 43\n",
      "cleaned number after removing negative classes: 40\n",
      "###############################################################################################\n",
      "2 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/0aT6ZBE3yco6RgfF-boldgrid_ss.png\n",
      "predicted number: 34\n",
      "denested number: 34\n",
      "cleaned number after removing negative classes: 31\n",
      "###############################################################################################\n",
      "3 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/1nMggJ5GIIEFbYeI-uncpress_ss.png\n",
      "predicted number: 30\n",
      "denested number: 30\n",
      "cleaned number after removing negative classes: 27\n",
      "###############################################################################################\n",
      "4 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/2eqOveJE5yU5wT43-2love_ss.png\n",
      "predicted number: 9\n",
      "denested number: 9\n",
      "cleaned number after removing negative classes: 7\n",
      "###############################################################################################\n",
      "5 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/2gtBmWcoqrZKtL3A-covasoftware_ss.png\n",
      "predicted number: 19\n",
      "denested number: 19\n",
      "cleaned number after removing negative classes: 18\n",
      "###############################################################################################\n",
      "6 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/3Fty1G9fsbG8f8e2-entiretest_ss.png\n",
      "predicted number: 38\n",
      "denested number: 38\n",
      "cleaned number after removing negative classes: 38\n",
      "###############################################################################################\n",
      "7 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/3NyyM0qW08CRbchv-squarespace_ss.png\n",
      "predicted number: 33\n",
      "denested number: 33\n",
      "cleaned number after removing negative classes: 28\n",
      "###############################################################################################\n",
      "8 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/4c7JWiP3yKALOQw8-hans-zimmer_ss.png\n",
      "predicted number: 46\n",
      "denested number: 46\n",
      "cleaned number after removing negative classes: 43\n",
      "###############################################################################################\n",
      "9 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/5Oig4yqbk5Luwuu3-erome_ss.png\n",
      "predicted number: 9\n",
      "denested number: 9\n",
      "cleaned number after removing negative classes: 9\n",
      "###############################################################################################\n",
      "10 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/5S0ntCXd3jFIzuCE-multistatesociety_ss.png\n",
      "predicted number: 26\n",
      "denested number: 26\n",
      "cleaned number after removing negative classes: 24\n",
      "###############################################################################################\n",
      "11 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/5fXW9aZnxNP5f4E6-cbsnews_ss.png\n",
      "predicted number: 27\n",
      "denested number: 27\n",
      "cleaned number after removing negative classes: 24\n",
      "###############################################################################################\n",
      "12 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/6NVbPqj48y9ThvwT-readthedocs_ss.png\n",
      "predicted number: 33\n",
      "denested number: 33\n",
      "cleaned number after removing negative classes: 29\n",
      "###############################################################################################\n",
      "13 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/6TEnqJ29XsX8kJpd-games2gether_ss.png\n",
      "predicted number: 42\n",
      "denested number: 42\n",
      "cleaned number after removing negative classes: 37\n",
      "###############################################################################################\n",
      "14 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/6gFw7bP2szwMmY3G-worldtimebuddy_ss.png\n",
      "predicted number: 31\n",
      "denested number: 31\n",
      "cleaned number after removing negative classes: 28\n",
      "###############################################################################################\n",
      "15 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/70prigfU3y7EidTs-thrivent_ss.png\n",
      "predicted number: 25\n",
      "denested number: 25\n",
      "cleaned number after removing negative classes: 23\n",
      "###############################################################################################\n",
      "16 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/7aMKiJmX6TZwNtSg-coloradosbdc_ss.png\n",
      "predicted number: 8\n",
      "denested number: 8\n",
      "cleaned number after removing negative classes: 4\n",
      "###############################################################################################\n",
      "17 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/82JriSNl6GYwvA8M-etranslate_ss.png\n",
      "predicted number: 18\n",
      "denested number: 18\n",
      "cleaned number after removing negative classes: 18\n",
      "###############################################################################################\n",
      "18 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/9GGgWUZTjIoHvD8B-tacojohns_ss.png\n",
      "predicted number: 23\n",
      "denested number: 23\n",
      "cleaned number after removing negative classes: 21\n",
      "###############################################################################################\n",
      "19 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/BRf2llG8abG8XQqf-shopzilla_ss.png\n",
      "predicted number: 15\n",
      "denested number: 15\n",
      "cleaned number after removing negative classes: 14\n",
      "###############################################################################################\n",
      "20 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/DUvF9dshsgZPicV6-charlestonwineandfood_ss.png\n",
      "predicted number: 19\n",
      "denested number: 19\n",
      "cleaned number after removing negative classes: 18\n",
      "###############################################################################################\n",
      "21 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/E11t3Z47O6stOyDQ-cantunsee_ss.png\n",
      "predicted number: 22\n",
      "denested number: 22\n",
      "cleaned number after removing negative classes: 22\n",
      "###############################################################################################\n",
      "22 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/E7hEdIaeabC5bw27-taichiforhealthinstitute_ss.png\n",
      "predicted number: 25\n",
      "denested number: 25\n",
      "cleaned number after removing negative classes: 25\n",
      "###############################################################################################\n",
      "23 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/Ef6vKkCgKxxyiKU9-mumsandmothers_ss.png\n",
      "predicted number: 26\n",
      "denested number: 26\n",
      "cleaned number after removing negative classes: 26\n",
      "###############################################################################################\n",
      "24 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/EnEogrLBn43sPmrb-zemanta_ss.png\n",
      "predicted number: 32\n",
      "denested number: 32\n",
      "cleaned number after removing negative classes: 25\n",
      "###############################################################################################\n",
      "25 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/F0aV6PjF356lX0yJ-beagleboard_ss.png\n",
      "predicted number: 34\n",
      "denested number: 34\n",
      "cleaned number after removing negative classes: 33\n",
      "###############################################################################################\n",
      "26 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/FYtLhjTVvEzj9MOV-empireminers_ss.png\n",
      "predicted number: 33\n",
      "denested number: 33\n",
      "cleaned number after removing negative classes: 31\n",
      "###############################################################################################\n",
      "27 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/FvX20nETlFpbQQa7-missourireview_ss.png\n",
      "predicted number: 28\n",
      "denested number: 28\n",
      "cleaned number after removing negative classes: 28\n",
      "###############################################################################################\n",
      "28 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/Gw9Bj5ae43JDlIfX-glfin_ss.png\n",
      "predicted number: 7\n",
      "denested number: 7\n",
      "cleaned number after removing negative classes: 7\n",
      "###############################################################################################\n",
      "29 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/H4RlP4LbBDEMV6QN-web2appz_ss.png\n",
      "predicted number: 29\n",
      "denested number: 29\n",
      "cleaned number after removing negative classes: 26\n",
      "###############################################################################################\n",
      "30 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/Hqoa3Z5mqBmGDB0a-hulu_ss.png\n",
      "predicted number: 11\n",
      "denested number: 11\n",
      "cleaned number after removing negative classes: 9\n",
      "###############################################################################################\n",
      "31 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/IWAXp9ltBQdHJLtF-japansociety_ss.png\n",
      "predicted number: 18\n",
      "denested number: 18\n",
      "cleaned number after removing negative classes: 15\n",
      "###############################################################################################\n",
      "32 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/J0kswR4Vpb4mXK2Y-theabyss_ss.png\n",
      "predicted number: 43\n",
      "denested number: 43\n",
      "cleaned number after removing negative classes: 38\n",
      "###############################################################################################\n",
      "33 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/J3e1ZKeOYAOmdSR7-revisionmilitary_ss.png\n",
      "predicted number: 40\n",
      "denested number: 40\n",
      "cleaned number after removing negative classes: 38\n",
      "###############################################################################################\n",
      "34 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/JLwboLxddYDJDwqV-orvium_ss.png\n",
      "predicted number: 10\n",
      "denested number: 10\n",
      "cleaned number after removing negative classes: 9\n",
      "###############################################################################################\n",
      "35 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/K8JgZMCms5Wnp9WP-scherstad_ss.png\n",
      "predicted number: 26\n",
      "denested number: 26\n",
      "cleaned number after removing negative classes: 23\n",
      "###############################################################################################\n",
      "36 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/KAQHpVivvgYcC7wc-baldhiker_ss.png\n",
      "predicted number: 14\n",
      "denested number: 14\n",
      "cleaned number after removing negative classes: 13\n",
      "###############################################################################################\n",
      "37 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/KZlulgg0WAp1Xjl7-digitalsanyog_ss.png\n",
      "predicted number: 11\n",
      "denested number: 11\n",
      "cleaned number after removing negative classes: 11\n",
      "###############################################################################################\n",
      "38 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/LCAuGGFSkHx9m42i-projectreportinfo_ss.png\n",
      "predicted number: 34\n",
      "denested number: 34\n",
      "cleaned number after removing negative classes: 31\n",
      "###############################################################################################\n",
      "39 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/LQrt8MEiYefSYML6-principalam_ss.png\n",
      "predicted number: 10\n",
      "denested number: 10\n",
      "cleaned number after removing negative classes: 10\n",
      "###############################################################################################\n",
      "40 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/M5Mn5WME3gcMIaY8-unsimpleworld_ss.png\n",
      "predicted number: 7\n",
      "denested number: 7\n",
      "cleaned number after removing negative classes: 5\n",
      "###############################################################################################\n",
      "41 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/MFHGD8NPPO3q1Of9-addgoodsites_ss.png\n",
      "predicted number: 38\n",
      "denested number: 38\n",
      "cleaned number after removing negative classes: 35\n",
      "###############################################################################################\n",
      "42 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/MjSd43Jv92YtVBWb-hootsuite_ss.png\n",
      "predicted number: 28\n",
      "denested number: 28\n",
      "cleaned number after removing negative classes: 26\n",
      "###############################################################################################\n",
      "43 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/MkEABb3cZZrSNuia-prescottvalley-az_ss.png\n",
      "predicted number: 30\n",
      "denested number: 30\n",
      "cleaned number after removing negative classes: 26\n",
      "###############################################################################################\n",
      "44 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/MsUMKz97DidzKtEI-itp_ss.png\n",
      "predicted number: 19\n",
      "denested number: 19\n",
      "cleaned number after removing negative classes: 15\n",
      "###############################################################################################\n",
      "45 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/N4TUoQErcbArIXox-powerbi_ss.png\n",
      "predicted number: 9\n",
      "denested number: 9\n",
      "cleaned number after removing negative classes: 8\n",
      "###############################################################################################\n",
      "46 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/NW1j4l09inOaiCCL-xtistore_ss.png\n",
      "predicted number: 26\n",
      "denested number: 26\n",
      "cleaned number after removing negative classes: 22\n",
      "###############################################################################################\n",
      "47 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/Ni6GYgWrPBTmNJtS-addevent_ss.png\n",
      "predicted number: 31\n",
      "denested number: 31\n",
      "cleaned number after removing negative classes: 31\n",
      "###############################################################################################\n",
      "48 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/Ofb9Wt8dLOlGMzhz-rallomarketing_ss.png\n",
      "predicted number: 20\n",
      "denested number: 20\n",
      "cleaned number after removing negative classes: 20\n",
      "###############################################################################################\n",
      "49 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/P3yPV38PhrI2zHPY-wisetack_ss.png\n",
      "predicted number: 14\n",
      "denested number: 14\n",
      "cleaned number after removing negative classes: 14\n",
      "###############################################################################################\n",
      "50 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/PjJpi8I4yf0iH04l-ivrose_ss.png\n",
      "predicted number: 56\n",
      "denested number: 56\n",
      "cleaned number after removing negative classes: 55\n",
      "###############################################################################################\n",
      "51 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/QhOPqLfP8MWFSKWE-cta-observatory_ss.png\n",
      "predicted number: 40\n",
      "denested number: 40\n",
      "cleaned number after removing negative classes: 37\n",
      "###############################################################################################\n",
      "52 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/RIn08D69umJMgRGa-vanderbilt_ss.png\n",
      "predicted number: 4\n",
      "denested number: 4\n",
      "cleaned number after removing negative classes: 4\n",
      "###############################################################################################\n",
      "53 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/SlvlUlc91FJZ6S3e-vidoomy_ss.png\n",
      "predicted number: 20\n",
      "denested number: 20\n",
      "cleaned number after removing negative classes: 18\n",
      "###############################################################################################\n",
      "54 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/TkxY5Yo2TkkBnRjA-umbrelladstudio_ss.png\n",
      "predicted number: 15\n",
      "denested number: 15\n",
      "cleaned number after removing negative classes: 15\n",
      "###############################################################################################\n",
      "55 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/TlbR1d8Mg45uFXnr-uni-trier_ss.png\n",
      "predicted number: 35\n",
      "denested number: 35\n",
      "cleaned number after removing negative classes: 33\n",
      "###############################################################################################\n",
      "56 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/UX6D6740QeEjy45v-hostpro2u_ss.png\n",
      "predicted number: 24\n",
      "denested number: 24\n",
      "cleaned number after removing negative classes: 22\n",
      "###############################################################################################\n",
      "57 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/VEgzKJhvOSHHZrqi-colorlib_ss.png\n",
      "predicted number: 14\n",
      "denested number: 14\n",
      "cleaned number after removing negative classes: 14\n",
      "###############################################################################################\n",
      "58 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/VPmbTtwu4AVRjCIW-111topwin_ss.png\n",
      "predicted number: 22\n",
      "denested number: 22\n",
      "cleaned number after removing negative classes: 20\n",
      "###############################################################################################\n",
      "59 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/VePoGYunRHFLdOjc-tudelft_ss.png\n",
      "predicted number: 21\n",
      "denested number: 21\n",
      "cleaned number after removing negative classes: 20\n",
      "###############################################################################################\n",
      "60 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/XloANqOHKYJdTXY6-hindawi_ss.png\n",
      "predicted number: 39\n",
      "denested number: 39\n",
      "cleaned number after removing negative classes: 33\n",
      "###############################################################################################\n",
      "61 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/ZJuArKFt1q1lnX0u-questhealth_ss.png\n",
      "predicted number: 36\n",
      "denested number: 36\n",
      "cleaned number after removing negative classes: 36\n",
      "###############################################################################################\n",
      "62 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/ZYpZmJYQsCEUIu8l-estense_ss.png\n",
      "predicted number: 17\n",
      "denested number: 17\n",
      "cleaned number after removing negative classes: 16\n",
      "###############################################################################################\n",
      "63 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/blDvzwY8AdGDwn4H-maxxis_ss.png\n",
      "predicted number: 34\n",
      "denested number: 34\n",
      "cleaned number after removing negative classes: 33\n",
      "###############################################################################################\n",
      "64 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/cAZC9G5PIyjMpI9g-force_ss.png\n",
      "predicted number: 40\n",
      "denested number: 40\n",
      "cleaned number after removing negative classes: 38\n",
      "###############################################################################################\n",
      "65 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/cDMsfCki9Qdu7BaY-insideoursuitcase_ss.png\n",
      "predicted number: 20\n",
      "denested number: 20\n",
      "cleaned number after removing negative classes: 20\n",
      "###############################################################################################\n",
      "66 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/cZFubd2nRqBopZCn-aitextpromptgenerator_ss.png\n",
      "predicted number: 30\n",
      "denested number: 30\n",
      "cleaned number after removing negative classes: 26\n",
      "###############################################################################################\n",
      "67 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/dJfc9oTDHRA6aJ1i-attentioninsight_ss.png\n",
      "predicted number: 27\n",
      "denested number: 27\n",
      "cleaned number after removing negative classes: 26\n",
      "###############################################################################################\n",
      "68 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/dWYCqJ0fMCfUuenw-askubuntu_ss.png\n",
      "predicted number: 44\n",
      "denested number: 44\n",
      "cleaned number after removing negative classes: 42\n",
      "###############################################################################################\n",
      "69 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/diqOCwOc6W1nKSfH-meanwhilespace_ss.png\n",
      "predicted number: 19\n",
      "denested number: 19\n",
      "cleaned number after removing negative classes: 16\n",
      "###############################################################################################\n",
      "70 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/eOhc3UfoVrbtc3Zx-mightyforms_ss.png\n",
      "predicted number: 32\n",
      "denested number: 32\n",
      "cleaned number after removing negative classes: 32\n",
      "###############################################################################################\n",
      "71 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/eW0nJnXnt0NoTDst-prosportsdaily_ss.png\n",
      "predicted number: 35\n",
      "denested number: 35\n",
      "cleaned number after removing negative classes: 33\n",
      "###############################################################################################\n",
      "72 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/eYjb1jLWxWRbxUWU-twago_ss.png\n",
      "predicted number: 13\n",
      "denested number: 13\n",
      "cleaned number after removing negative classes: 12\n",
      "###############################################################################################\n",
      "73 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/fLOIqJG1TOGKt8fW-gov_ss.png\n",
      "predicted number: 21\n",
      "denested number: 21\n",
      "cleaned number after removing negative classes: 18\n",
      "###############################################################################################\n",
      "74 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/hGkzMJRoc15DAipl-novaloca_ss.png\n",
      "predicted number: 21\n",
      "denested number: 21\n",
      "cleaned number after removing negative classes: 18\n",
      "###############################################################################################\n",
      "75 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/hprJaHCYCAzztzyz-wildyeastblog_ss.png\n",
      "predicted number: 16\n",
      "denested number: 16\n",
      "cleaned number after removing negative classes: 13\n",
      "###############################################################################################\n",
      "76 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/j8DLHPIc1kImu3dX-thzthehealingzone_ss.png\n",
      "predicted number: 27\n",
      "denested number: 27\n",
      "cleaned number after removing negative classes: 26\n",
      "###############################################################################################\n",
      "77 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/jSwFpI9k1umwpFig-mioggi_ss.png\n",
      "predicted number: 11\n",
      "denested number: 11\n",
      "cleaned number after removing negative classes: 9\n",
      "###############################################################################################\n",
      "78 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/jgKryh4PcwWY2F8W-glassdoor_ss.png\n",
      "predicted number: 4\n",
      "denested number: 4\n",
      "cleaned number after removing negative classes: 3\n",
      "###############################################################################################\n",
      "79 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/mA6LC5AybBE15Bb1-k4tube_ss.png\n",
      "predicted number: 23\n",
      "denested number: 23\n",
      "cleaned number after removing negative classes: 19\n",
      "###############################################################################################\n",
      "80 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/mUfBqOGdK6DRx98B-imca-int_ss.png\n",
      "predicted number: 18\n",
      "denested number: 18\n",
      "cleaned number after removing negative classes: 16\n",
      "###############################################################################################\n",
      "81 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/mcGdzJSXK9Y2v6X2-gtomoxetine_ss.png\n",
      "predicted number: 16\n",
      "denested number: 16\n",
      "cleaned number after removing negative classes: 16\n",
      "###############################################################################################\n",
      "82 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/pWKMAFuVjgANeoBT-ouo_ss.png\n",
      "predicted number: 5\n",
      "denested number: 5\n",
      "cleaned number after removing negative classes: 5\n",
      "###############################################################################################\n",
      "83 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/qK5pUExGFMU9hzbw-benefitspro_ss.png\n",
      "predicted number: 33\n",
      "denested number: 33\n",
      "cleaned number after removing negative classes: 30\n",
      "###############################################################################################\n",
      "84 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/qnLmlgMn1sHbZN6h-jscalc-blog_ss.png\n",
      "predicted number: 32\n",
      "denested number: 32\n",
      "cleaned number after removing negative classes: 31\n",
      "###############################################################################################\n",
      "85 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/rPfcXKODc2jSu4ef-mapsonline_ss.png\n",
      "predicted number: 15\n",
      "denested number: 15\n",
      "cleaned number after removing negative classes: 15\n",
      "###############################################################################################\n",
      "86 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/t3XiZxQXnt6Y59hj-lawdim_ss.png\n",
      "predicted number: 32\n",
      "denested number: 32\n",
      "cleaned number after removing negative classes: 29\n",
      "###############################################################################################\n",
      "87 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/tscsaBGWOsXpsw4E-thefreshgrocer_ss.png\n",
      "predicted number: 34\n",
      "denested number: 34\n",
      "cleaned number after removing negative classes: 32\n",
      "###############################################################################################\n",
      "88 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/ubXYULdLHLElR6WB-biltmorehotel_ss.png\n",
      "predicted number: 31\n",
      "denested number: 31\n",
      "cleaned number after removing negative classes: 31\n",
      "###############################################################################################\n",
      "89 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/ufS3CXd4Eelx4ZRi-vuejs_ss.png\n",
      "predicted number: 39\n",
      "denested number: 39\n",
      "cleaned number after removing negative classes: 37\n",
      "###############################################################################################\n",
      "90 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/vaSBmdmGJcFgWkUS-winthrop_ss.png\n",
      "predicted number: 27\n",
      "denested number: 27\n",
      "cleaned number after removing negative classes: 22\n",
      "###############################################################################################\n",
      "91 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/w92RnO87J32fCYOK-mountauburn_ss.png\n",
      "predicted number: 25\n",
      "denested number: 25\n",
      "cleaned number after removing negative classes: 20\n",
      "###############################################################################################\n",
      "92 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/wf08RftbVUTFCl9C-buyxmedpro_ss.png\n",
      "predicted number: 15\n",
      "denested number: 15\n",
      "cleaned number after removing negative classes: 14\n",
      "###############################################################################################\n",
      "93 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/wvn4TImjNINpVOao-welcomheritagehotels_ss.png\n",
      "predicted number: 40\n",
      "denested number: 40\n",
      "cleaned number after removing negative classes: 38\n",
      "###############################################################################################\n",
      "94 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/yYEUPTybX9atRYK7-megapira_ss.png\n",
      "predicted number: 17\n",
      "denested number: 17\n",
      "cleaned number after removing negative classes: 17\n",
      "###############################################################################################\n",
      "95 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/ydQxHUhcJ0EnWB17-householdadvice_ss.png\n",
      "predicted number: 16\n",
      "denested number: 16\n",
      "cleaned number after removing negative classes: 15\n",
      "###############################################################################################\n",
      "96 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/ypiS1D8tMUwqy7om-traffickingresourcecenter_ss.png\n",
      "predicted number: 33\n",
      "denested number: 33\n",
      "cleaned number after removing negative classes: 27\n",
      "###############################################################################################\n",
      "97 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/zAyiwF3zbaBld2FW-inedo_ss.png\n",
      "predicted number: 25\n",
      "denested number: 25\n",
      "cleaned number after removing negative classes: 24\n",
      "###############################################################################################\n",
      "98 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/zYuk19uI8JwwhWO2-megacompuworldjaipur_ss.png\n",
      "predicted number: 50\n",
      "denested number: 50\n",
      "cleaned number after removing negative classes: 47\n",
      "###############################################################################################\n",
      "99 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/zaEPn4SH1r82Zn1M-augmentin_ss.png\n",
      "predicted number: 18\n",
      "denested number: 18\n",
      "cleaned number after removing negative classes: 17\n",
      "writing out results to ./res_out_dir/results.json\n"
     ]
    }
   ],
   "source": [
    "master_det_dict = []\n",
    "\n",
    "for i, img_path in enumerate(img_path_list):\n",
    "\n",
    "    vis_outpath = os.path.join(vis_out_dir, os.path.basename(img_path))\n",
    "\n",
    "    # Creating master dictionary of detected elements\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    pred_out_list = []\n",
    "    for od_pred in obj_det_pred_list:\n",
    "        pred_out_list.append(od_pred(img))\n",
    "    outputs = merge_outputs(pred_out_list)\n",
    "    \n",
    "    print('###############################################################################################')\n",
    "    print(i, img_path)\n",
    "    \n",
    "    data_dict = createDataDict(img_path, outputs)\n",
    "    pred_bbox_list = [ann[\"bbox\"] for ann in data_dict[\"annotations\"]]\n",
    "\n",
    "    print(\"predicted number:\", len(data_dict[\"annotations\"]))\n",
    "    \n",
    "    if denest:\n",
    "        rem_ind_list = filter_nested_bboxes(pred_bbox_list, denest_thold)\n",
    "        for ind in sorted(rem_ind_list, reverse=True):\n",
    "            del data_dict['annotations'][ind]\n",
    "            del pred_bbox_list[ind]\n",
    "\n",
    "    print(\"denested number:\", len(data_dict[\"annotations\"]))\n",
    "\n",
    "    if keep_clickable_elems_only:\n",
    "        nce_list, ce_bbox_list = get_non_clickable_elem_ind_list(img_path, pred_bbox_list)\n",
    "\n",
    "        if nce_list == None and ce_bbox_list == None:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "\n",
    "            print('non clickable', len(nce_list))\n",
    "            print('clickable', len(ce_bbox_list))\n",
    "\n",
    "            z_list = ['0' for _ in range(len(ce_bbox_list))]\n",
    "            \n",
    "            draw_bounding_boxes(img_path, ce_bbox_list, z_list, vis_outpath, color='green')\n",
    "\n",
    "            for ind in sorted(nce_list, reverse=True):\n",
    "                data_dict[\"annotations\"].pop(ind)\n",
    "                pred_bbox_list.pop(ind)\n",
    "\n",
    "            print(\"cleaned number after removing non clickable elements:\", len(data_dict[\"annotations\"]))\n",
    "\n",
    "    elem_img_list = process_image(data_dict[\"file_name\"], pred_bbox_list, padding, bg_color, border)\n",
    "    \n",
    "    pred_ids = []\n",
    "    pred_classes = []\n",
    "    remove_list = []\n",
    "    \n",
    "    for j, img in enumerate(elem_img_list):\n",
    "        \n",
    "        img_t = transform(img.convert('RGB')).unsqueeze(0).to('cuda')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = classifier(img_t)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        # OG\n",
    "        # pred_class_id = str(predicted.item() + 1)\n",
    "        pred_class_id = str(predicted.item())\n",
    "        pred_class_name = cats[pred_class_id]\n",
    "        \n",
    "        if remove_neg and pred_class_id == neg_class_id:\n",
    "            remove_list.append(j)\n",
    "\n",
    "        pred_ids.append(pred_class_id)\n",
    "        pred_classes.append(pred_classes)\n",
    "        # data_dict[\"annotations\"][j][\"category_id\"] = int(pred_class_id)\n",
    "        data_dict[\"annotations\"][j][\"category_id\"] = pred_class_name\n",
    "    \n",
    "    if remove_neg and remove_list:\n",
    "         for ind in sorted(remove_list, reverse=True):\n",
    "            data_dict[\"annotations\"].pop(ind)\n",
    "            pred_bbox_list.pop(ind)\n",
    "            pred_ids.pop(ind)\n",
    "            pred_classes.pop(ind)\n",
    "            \n",
    "    print(\"cleaned number after removing negative classes:\", len(data_dict[\"annotations\"]))\n",
    "    \n",
    "    if os.path.exists(vis_outpath):\n",
    "        draw_bounding_boxes(vis_outpath, pred_bbox_list, pred_ids, vis_outpath, color='red')\n",
    "    else:\n",
    "        draw_bounding_boxes(img_path, pred_bbox_list, pred_ids, vis_outpath, color='red')\n",
    "    \n",
    "    master_det_dict.append(data_dict)\n",
    "    \n",
    "res_outpath = os.path.join(res_out_dir, \"results.json\")\n",
    "print(\"writing out results to\", res_outpath)\n",
    "with open(res_outpath, 'w+') as f:\n",
    "    json.dump(master_det_dict, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "int_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
