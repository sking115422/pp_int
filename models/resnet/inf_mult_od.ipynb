{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/int_venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import glob\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.structures.instances import Instances\n",
    "from multiprocessing import Process, Manager\n",
    "import gc\n",
    "from PIL import Image, ImageDraw, ImageFont\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PATHS\n",
    "# Do not use directory with negatives\n",
    "in_dir = \"/mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10\"\n",
    "# in_dir = \"/mnt/nis_lab_research/data/coco_files/og/test/ft_test1\"\n",
    "res_out_dir = \"./res_out_dir\"\n",
    "vis_out_dir = \"./res_out_dir/vis\"\n",
    "# cat_path = \"/mnt/nis_lab_research/data/elem_cat/cat_neg_27.json\"\n",
    "cat_path = \"/mnt/nis_lab_research/data/elem_cat/cat_neg_10.json\"\n",
    "master_url_dict_path = '/mnt/nis_lab_research/data/top-1m/top-1m-mapping.json'\n",
    "\n",
    "\n",
    "# OBJECT DETECTOR MODELS\n",
    "# # 2 OD\n",
    "od_paths = [\n",
    "    (\"/mnt/nis_lab_research/data/coco_files/agg/class_2_rem/out/far_shah_b1-b5_b8_train_c0/model_final.pth\", 0.50), # small\n",
    "    (\"/mnt/nis_lab_research/data/coco_files/agg/class_2_rem/out/far_shah_b1-b5_b8_train_c1/model_final.pth\", 0.75)  # large\n",
    "]\n",
    "\n",
    "# # 10 OD\n",
    "# od_paths = [\n",
    "#     (\"/mnt/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c0/model_final.pth\", .75),\n",
    "#     (\"/mnt/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c1/model_final.pth\", .75),\n",
    "#     (\"/mnt/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c2/model_final.pth\", .75),\n",
    "#     (\"/mnt/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c3/model_final.pth\", .75),\n",
    "#     (\"/mnt/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c4/model_final.pth\", .75),\n",
    "#     (\"/mnt/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c5/model_final.pth\", .75),\n",
    "#     (\"/mnt/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c6/model_final.pth\", .75),\n",
    "#     (\"/mnt/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c7/model_final.pth\", .75),\n",
    "#     (\"/mnt/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c8/model_final.pth\", .75),\n",
    "#     (\"/mnt/nis_lab_research/data/coco_files/agg/class_1_rem/out/far_shah_b1-b5_b8_train_c9/model_final.pth\", .75)\n",
    "# ]\n",
    "\n",
    "# CLASSIFIER MODEL\n",
    "# # 10 Class Agg + Neg\n",
    "# class_path = \"/mnt/nis_lab_research/data/class_data/pth/far_shah_b1-b5_b8_train_c10_neg/model_final.pth\"\n",
    "class_path = \"/mnt/nis_lab_research/data/class_data/pth/full_train_neg_c10/model_final.pth\"\n",
    "# 27 Class + Neg\n",
    "# class_path = \"/mnt/nis_lab_research/data/class_data/pth/far_shah_b1-b5_b8_train_neg/model_final.pth\"\n",
    "\n",
    "# ADJUSTABLES\n",
    "bg_color = \"white\"\n",
    "# Possibly adjust padding to fixed value in the future\n",
    "padding = 0.15\n",
    "border = 0\n",
    "# If True negatively identified cases will be removed before calulating metrics\n",
    "remove_neg = True\n",
    "keep_clickable_elems_only = True\n",
    "iou_thold = .5\n",
    "neg_class_name = \"Random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting CUDA devices as visible\n",
    "cuda_devices = \"2,3\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CUDA devices:\n",
      "  0: Tesla P100-PCIE-16GB\n",
      "  1: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "available_devices = [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]\n",
    "print(\"Available CUDA devices:\")\n",
    "for i, device_name in enumerate(available_devices):\n",
    "    print(f\"  {i}: {device_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soi(str1, start_char, end_char):\n",
    "    str1 = str(str1)\n",
    "    offst = len(start_char)\n",
    "    ind1 = str1.find(start_char)\n",
    "    ind2 = str1.find(end_char)\n",
    "    s_str = str1[ind1+offst:ind2]\n",
    "    return s_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bbox_xywh(b):\n",
    "    x1, y1, x2, y2 = b\n",
    "    x = x1\n",
    "    y = y1\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    return [x, y, w, h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createDataDict (fn, outputs):\n",
    "    img_shape = list(outputs[\"instances\"].image_size)\n",
    "    img_h = int(img_shape[0])\n",
    "    img_w = int(img_shape[1])\n",
    "    ann_list = []\n",
    "\n",
    "    class_list = get_soi(outputs[\"instances\"].pred_classes, \"[\", \"]\").split(\",\")\n",
    "    \n",
    "    if class_list[0] != \"\":\n",
    "\n",
    "        class_list_new = []\n",
    "        for each in class_list:\n",
    "            if each.strip().isdigit():\n",
    "                class_list_new.append(int(each.strip()))\n",
    "            else:\n",
    "                print(f\"Invalid class ID: {each}\")\n",
    "\n",
    "        bbox_list = get_soi(outputs[\"instances\"].pred_boxes, \"[[\", \"]]\").split(\"]\")\n",
    "        bbox_list_new = []\n",
    "        for each in bbox_list:\n",
    "            bbox = re.sub(\"['[,\\n]\", \"\", each).split(\" \")\n",
    "            bbox_new = []\n",
    "            for item in bbox:\n",
    "                if item != \"\":\n",
    "                    bbox_new.append(float(item))\n",
    "            bbox_new = convert_bbox_xywh(bbox_new)\n",
    "            bbox_list_new.append(bbox_new)\n",
    "\n",
    "        for i in range(0, len(class_list)):\n",
    "            # og was \"bbox_mode\": \"<BoxMode.XYWH_ABS: 1>\"\n",
    "            ann_list.append({\"iscrowd\": 0, \"bbox\": bbox_list_new[i], \"category_id\": class_list_new[i], \"bbox_mode\": 0})\n",
    "    \n",
    "    data_dict = {\n",
    "        \"file_name\": fn,\n",
    "        \"height\": img_h,\n",
    "        \"width\": img_w, \n",
    "        \"annotations\": ann_list\n",
    "    }\n",
    " \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(file_path, bounding_box, padding):\n",
    "    \n",
    "    with Image.open(file_path) as img:\n",
    "        \n",
    "        x_min, y_min, width, height = bounding_box\n",
    "\n",
    "        # Calculate padding in pixels\n",
    "        pad_width = int(width * padding)\n",
    "        pad_height = int(height * padding)\n",
    "\n",
    "        # Adjust the bounding box with padding\n",
    "        x_min = max(x_min - pad_width, 0)\n",
    "        y_min = max(y_min - pad_height, 0)\n",
    "        x1 = min(x_min + width + 2 * pad_width, img.width)\n",
    "        y1 = min(y_min + height + 2 * pad_height, img.height)\n",
    "        \n",
    "        cropped_img = img.crop((x_min, y_min, x1, y1))\n",
    "        \n",
    "        return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paste_to_bg(image, background_color, bg_width, bg_height):\n",
    "    \n",
    "    # Create a new image with the specified background color and dimensions\n",
    "    background = Image.new('RGB', (bg_width, bg_height), background_color)\n",
    "\n",
    "    # Calculate the position to paste the image so it's centered\n",
    "    x = (bg_width - image.width) // 2\n",
    "    y = (bg_height - image.height) // 2\n",
    "\n",
    "    # Paste the image onto the background\n",
    "    background.paste(image, (x, y), image if image.mode == 'RGBA' else None)\n",
    "\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_ar_lock(img, target_size):\n",
    "\n",
    "    original_width, original_height = img.size\n",
    "    target_width, target_height = target_size\n",
    "\n",
    "    # Calculate scaling factor\n",
    "    scaling_factor = min(target_width / original_width, target_height / original_height)\n",
    "\n",
    "    # Calculate new dimensions\n",
    "    new_width = max(int(original_width * scaling_factor), 1)\n",
    "    new_height = max(int(original_height * scaling_factor), 1)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = img.resize((new_width, new_height))\n",
    "\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rand_str(length):\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    random_string = ''.join(random.choice(characters) for i in range(length))\n",
    "    return random_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img_fp, bbox_list, padding, bg_color, border):\n",
    "    \n",
    "    # Create an empty list to store processed images\n",
    "    processed_images = []\n",
    "\n",
    "    for j, bbox in enumerate(bbox_list):\n",
    "\n",
    "        try:\n",
    "            elem_img = crop_image(img_fp, bbox, padding)\n",
    "            e_w = elem_img.size[0]\n",
    "            e_h = elem_img.size[1]\n",
    "\n",
    "            if e_w < e_h:\n",
    "                elem_img = paste_to_bg(elem_img, bg_color, e_h + border, e_h + border)\n",
    "            elif e_w > e_h:\n",
    "                elem_img = paste_to_bg(elem_img, bg_color, e_w + border, e_w + border)\n",
    "                \n",
    "            # elem_img = transform(elem_img)\n",
    "            processed_images.append(elem_img)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(img_fp)\n",
    "            print(e)\n",
    "\n",
    "    # Return the list of processed images\n",
    "    return processed_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(image_path, bbox_list, label_list, output_path, color = 'red', thickness=2):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Load a font\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    # Draw bounding boxes and labels\n",
    "    for bbox, label in zip(bbox_list, label_list):\n",
    "        x, y, w, h = bbox\n",
    "        draw.rectangle([x, y, x+w, y+h], outline=color, width = 2)\n",
    "        draw.text((x, y), label, fill=color, font=font)\n",
    "\n",
    "    # Save the new image\n",
    "    image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes_in_mem(image, bbox_list, label_list, color='red', thickness=2):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    for bbox, label in zip(bbox_list, label_list):\n",
    "        x, y, w, h = bbox\n",
    "        draw.rectangle([x, y, x + w, y + h], outline=color, width=thickness)\n",
    "        draw.text((x, y), label, fill=color, font=font)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_outputs(outputs):\n",
    "    l = []\n",
    "    for out in outputs:\n",
    "        l.append(out[\"instances\"])\n",
    "    new = Instances.cat(l)\n",
    "    return {\"instances\": new}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_all_but_first_part(s):\n",
    "    parts = s.split('-')\n",
    "    if len(parts) > 1:\n",
    "        return '-'.join(parts[1:])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(res_out_dir):\n",
    "    shutil.rmtree(res_out_dir)\n",
    "os.makedirs(vis_out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_list = [os.path.join(in_dir, \"images\", img_path) for img_path in sorted(os.listdir(os.path.join(in_dir, \"images\")))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/28 03:38:01 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /mnt/nis_lab_research/data/coco_files/agg/class_2_rem/out/far_shah_b1-b5_b8_train_c0/model_final.pth ...\n",
      "\u001b[32m[06/28 03:38:04 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /mnt/nis_lab_research/data/coco_files/agg/class_2_rem/out/far_shah_b1-b5_b8_train_c1/model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "obj_det_pred_list = []\n",
    "\n",
    "for od in od_paths:\n",
    "    \n",
    "    setup_logger()\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "    # cfg.MODEL.WEIGHTS = os.path.join(\"/home/dtron2_user/ls_dtron2_full/model/output\", \"model_final.pth\")\n",
    "    cfg.MODEL.WEIGHTS = od[0]\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = od[1] \n",
    "    obj_det_pred = DefaultPredictor(cfg)\n",
    "    obj_det_pred_list.append(obj_det_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=11, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = torch.load(class_path)\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cat_path, 'r') as f:\n",
    "    cats = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_class_id = \"\"\n",
    "\n",
    "for key, value in cats.items():\n",
    "    if value == neg_class_name:\n",
    "        neg_class_id = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(master_url_dict_path) as f:\n",
    "    master_url_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clickable_elements(domains):\n",
    "\n",
    "    obj_list = []\n",
    "\n",
    "    for dom in domains:\n",
    "\n",
    "        print(dom)\n",
    "\n",
    "        url = f'https://{dom}'\n",
    "\n",
    "        cmd = ['node', '../../get_clickable_elems/get_clickable_elems.js', url]\n",
    "        try:\n",
    "            result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
    "            print(result.stdout)  # Print the standard output from the command\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error executing command: {e}\")\n",
    "            print(f\"Command output: {e.output}\")\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        json_path = os.path.join('./data', f'{dom}.json' )\n",
    "        if os.path.exists(json_path):\n",
    "            with open(json_path) as f:\n",
    "                jobj = json.load(f)\n",
    "\n",
    "            obj_list.append(jobj)\n",
    "\n",
    "            return obj_list\n",
    "\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(boxA, boxB):\n",
    "    # Convert from [x, y, w, h] to [x1, y1, x2, y2]\n",
    "    x1A, y1A, x2A, y2A = boxA[0], boxA[1], boxA[0] + boxA[2], boxA[1] + boxA[3]\n",
    "    x1B, y1B, x2B, y2B = boxB[0], boxB[1], boxB[0] + boxB[2], boxB[1] + boxB[3]\n",
    "    \n",
    "    # Determine the coordinates of the intersection rectangle\n",
    "    xA = max(x1A, x1B)\n",
    "    yA = max(y1A, y1B)\n",
    "    xB = min(x2A, x2B)\n",
    "    yB = min(y2A, y2B)\n",
    "    \n",
    "    # Compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    \n",
    "    # Compute the area of both the prediction and true bounding boxes\n",
    "    boxAArea = (x2A - x1A) * (y2A - y1A)\n",
    "    boxBArea = (x2B - x1B) * (y2B - y1B)\n",
    "    \n",
    "    # Compute the area of union\n",
    "    unionArea = boxAArea + boxBArea - interArea\n",
    "    \n",
    "    # Compute the Intersection over Union by dividing the intersection area by the union area\n",
    "    iou = interArea / unionArea\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_clickable_elem_ind_list(img_path, pred_bbox_list):\n",
    "    # Assuming the existence of keep_all_but_first_part, master_url_dict, get_clickable_elements, and calculate_iou\n",
    "    \n",
    "    # Extract the key from the image path\n",
    "    key = keep_all_but_first_part(img_path.split('/')[-1])[:-7]\n",
    "    \n",
    "    # Get the domain from the master_url_dict using the key\n",
    "    domain = master_url_dict.get(key)\n",
    "    if not domain:\n",
    "        raise ValueError(f\"Key {key} not found in master_url_dict\")\n",
    "\n",
    "    # Get clickable elements for the domain\n",
    "    ces = get_clickable_elements([domain])\n",
    "\n",
    "    if ces == None:\n",
    "        return None, None\n",
    "    else:\n",
    "        ces_obj = ces[0]\n",
    "\n",
    "\n",
    "        # Build list of clickable bounding boxes\n",
    "        clickable_bbox_list = [[ce['x'], ce['y'], ce['width'], ce['height']] for ce in ces_obj]\n",
    "\n",
    "        # List to hold non-clickable element indices\n",
    "        non_clickable_ind_list = []\n",
    "\n",
    "        # Check each predicted bounding box against clickable bounding boxes\n",
    "        for i, p_bbox in enumerate(pred_bbox_list):\n",
    "            is_non_clickable = True\n",
    "            for ces in ces_obj:\n",
    "                ces_bbox = [ces['x'], ces['y'], ces['width'], ces['height']]\n",
    "                iou_score = calculate_iou(p_bbox, ces_bbox)\n",
    "                if iou_score >= iou_thold:\n",
    "                    is_non_clickable = False\n",
    "                    break\n",
    "            if is_non_clickable:\n",
    "                non_clickable_ind_list.append(i)\n",
    "\n",
    "        return non_clickable_ind_list, clickable_bbox_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/int_venv/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/0UnHYuFgKVpkj5fl-climbkalymnos_ss.png\n",
      "predicted number: 28\n",
      "climbkalymnos.com\n",
      "2024-06-28 03:38:07 [info]: Attempt 1 to process https://climbkalymnos.com\n",
      "2024-06-28 03:38:08 [info]: Navigated to https://climbkalymnos.com\n",
      "2024-06-28 03:38:24 [info]: Successfully processed https://climbkalymnos.com\n",
      "\n",
      "non clickable 20\n",
      "clickable 23\n",
      "cleaned number after removing non clickable elements: 8\n",
      "cleaned number after removing negative classes: 7\n",
      "1 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/0XQJNLHix7U3ywoz-trollalley_ss.png\n",
      "predicted number: 43\n",
      "trollalley.com\n",
      "2024-06-28 03:38:29 [info]: Attempt 1 to process https://trollalley.com\n",
      "2024-06-28 03:38:30 [info]: Navigated to https://trollalley.com\n",
      "2024-06-28 03:38:39 [info]: Successfully processed https://trollalley.com\n",
      "\n",
      "non clickable 37\n",
      "clickable 95\n",
      "cleaned number after removing non clickable elements: 6\n",
      "cleaned number after removing negative classes: 6\n",
      "2 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/0aT6ZBE3yco6RgfF-boldgrid_ss.png\n",
      "predicted number: 34\n",
      "boldgrid.com\n",
      "2024-06-28 03:38:43 [info]: Attempt 1 to process https://boldgrid.com\n",
      "2024-06-28 03:38:44 [info]: Navigated to https://boldgrid.com\n",
      "2024-06-28 03:39:03 [info]: Successfully processed https://boldgrid.com\n",
      "\n",
      "non clickable 19\n",
      "clickable 45\n",
      "cleaned number after removing non clickable elements: 15\n",
      "cleaned number after removing negative classes: 15\n",
      "3 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/1nMggJ5GIIEFbYeI-uncpress_ss.png\n",
      "predicted number: 30\n",
      "uncpress.org\n",
      "2024-06-28 03:39:07 [info]: Attempt 1 to process https://uncpress.org\n",
      "2024-06-28 03:39:08 [info]: Navigated to https://uncpress.org\n",
      "2024-06-28 03:39:23 [info]: Successfully processed https://uncpress.org\n",
      "\n",
      "non clickable 23\n",
      "clickable 42\n",
      "cleaned number after removing non clickable elements: 7\n",
      "cleaned number after removing negative classes: 5\n",
      "4 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/2eqOveJE5yU5wT43-2love_ss.png\n",
      "predicted number: 9\n",
      "2love.earth\n",
      "2024-06-28 03:39:27 [info]: Attempt 1 to process https://2love.earth\n",
      "2024-06-28 03:39:31 [info]: Navigated to https://2love.earth\n",
      "2024-06-28 03:39:35 [info]: Successfully processed https://2love.earth\n",
      "\n",
      "non clickable 4\n",
      "clickable 17\n",
      "cleaned number after removing non clickable elements: 5\n",
      "cleaned number after removing negative classes: 4\n",
      "5 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/2gtBmWcoqrZKtL3A-covasoftware_ss.png\n",
      "predicted number: 19\n",
      "covasoftware.com\n",
      "2024-06-28 03:39:38 [info]: Attempt 1 to process https://covasoftware.com\n",
      "2024-06-28 03:39:38 [error]: Failed processing https://covasoftware.com on attempt 1: page.goto: net::ERR_CERT_COMMON_NAME_INVALID at https://covasoftware.com/\n",
      "Call log:\n",
      "  \u001b[2m- navigating to \"https://covasoftware.com/\", waiting until \"load\"\u001b[22m\n",
      "\n",
      "2024-06-28 03:39:38 [info]: Attempt 2 to process https://covasoftware.com\n",
      "2024-06-28 03:39:39 [error]: Failed processing https://covasoftware.com on attempt 2: page.goto: net::ERR_CERT_COMMON_NAME_INVALID at https://covasoftware.com/\n",
      "Call log:\n",
      "  \u001b[2m- navigating to \"https://covasoftware.com/\", waiting until \"load\"\u001b[22m\n",
      "\n",
      "2024-06-28 03:39:39 [info]: Attempt 3 to process https://covasoftware.com\n",
      "2024-06-28 03:39:39 [error]: Failed processing https://covasoftware.com on attempt 3: page.goto: net::ERR_CERT_COMMON_NAME_INVALID at https://covasoftware.com/\n",
      "Call log:\n",
      "  \u001b[2m- navigating to \"https://covasoftware.com/\", waiting until \"load\"\u001b[22m\n",
      "\n",
      "2024-06-28 03:39:39 [error]: Exceeded retry limit for https://covasoftware.com\n",
      "\n",
      "cleaned number after removing negative classes: 18\n",
      "6 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/3Fty1G9fsbG8f8e2-entiretest_ss.png\n",
      "predicted number: 38\n",
      "entiretest.com\n",
      "2024-06-28 03:39:43 [info]: Attempt 1 to process https://entiretest.com\n",
      "2024-06-28 03:39:44 [info]: Navigated to https://entiretest.com\n",
      "2024-06-28 03:39:44 [info]: Successfully processed https://entiretest.com\n",
      "\n",
      "non clickable 38\n",
      "clickable 6\n",
      "cleaned number after removing non clickable elements: 0\n",
      "cleaned number after removing negative classes: 0\n",
      "7 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/3NyyM0qW08CRbchv-squarespace_ss.png\n",
      "predicted number: 33\n",
      "squarespace.com\n",
      "2024-06-28 03:39:47 [info]: Attempt 1 to process https://squarespace.com\n",
      "2024-06-28 03:39:48 [info]: Navigated to https://squarespace.com\n",
      "2024-06-28 03:40:09 [error]: Failed processing https://squarespace.com on attempt 1: elementHandle.isEnabled: Element is not attached to the DOM\n",
      "Call log:\n",
      "  \u001b[2m- waiting for locator(':scope')\u001b[22m\n",
      "\u001b[2m  -   locator resolved to <a href=\"/imprint\" class=\"is-borderless footer-nav-…>EU Legal</a>\u001b[22m\n",
      "\n",
      "2024-06-28 03:40:09 [info]: Attempt 2 to process https://squarespace.com\n",
      "2024-06-28 03:40:09 [info]: Navigated to https://squarespace.com\n",
      "2024-06-28 03:40:32 [error]: Failed processing https://squarespace.com on attempt 2: elementHandle.isEnabled: Element is not attached to the DOM\n",
      "Call log:\n",
      "  \u001b[2m- waiting for locator(':scope')\u001b[22m\n",
      "\u001b[2m  -   locator resolved to <a href=\"/imprint\" class=\"is-borderless footer-nav-…>EU Legal</a>\u001b[22m\n",
      "\n",
      "2024-06-28 03:40:32 [info]: Attempt 3 to process https://squarespace.com\n",
      "2024-06-28 03:40:32 [info]: Navigated to https://squarespace.com\n",
      "2024-06-28 03:40:54 [error]: Failed processing https://squarespace.com on attempt 3: elementHandle.isEnabled: Element is not attached to the DOM\n",
      "Call log:\n",
      "  \u001b[2m- waiting for locator(':scope')\u001b[22m\n",
      "\u001b[2m  -   locator resolved to <a href=\"/imprint\" class=\"is-borderless footer-nav-…>EU Legal</a>\u001b[22m\n",
      "\n",
      "2024-06-28 03:40:54 [error]: Exceeded retry limit for https://squarespace.com\n",
      "\n",
      "cleaned number after removing negative classes: 28\n",
      "8 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/4c7JWiP3yKALOQw8-hans-zimmer_ss.png\n",
      "predicted number: 46\n",
      "hans-zimmer.com\n",
      "2024-06-28 03:41:00 [info]: Attempt 1 to process https://hans-zimmer.com\n",
      "2024-06-28 03:41:09 [info]: Navigated to https://hans-zimmer.com\n",
      "2024-06-28 03:41:44 [error]: Failed processing https://hans-zimmer.com on attempt 1: elementHandle.isEnabled: Element is not attached to the DOM\n",
      "Call log:\n",
      "  \u001b[2m- waiting for locator(':scope')\u001b[22m\n",
      "\u001b[2m  -   locator resolved to <div class=\"v-image__image v-image__image--preload v-…></div>\u001b[22m\n",
      "\n",
      "2024-06-28 03:41:44 [info]: Attempt 2 to process https://hans-zimmer.com\n",
      "2024-06-28 03:41:53 [info]: Navigated to https://hans-zimmer.com\n",
      "2024-06-28 03:42:29 [error]: Failed processing https://hans-zimmer.com on attempt 2: elementHandle.isEnabled: Element is not attached to the DOM\n",
      "Call log:\n",
      "  \u001b[2m- waiting for locator(':scope')\u001b[22m\n",
      "\u001b[2m  -   locator resolved to <div class=\"v-image__image v-image__image--preload v-…></div>\u001b[22m\n",
      "\n",
      "2024-06-28 03:42:29 [info]: Attempt 3 to process https://hans-zimmer.com\n",
      "2024-06-28 03:42:37 [info]: Navigated to https://hans-zimmer.com\n",
      "2024-06-28 03:43:14 [info]: Successfully processed https://hans-zimmer.com\n",
      "\n",
      "non clickable 31\n",
      "clickable 63\n",
      "cleaned number after removing non clickable elements: 15\n",
      "cleaned number after removing negative classes: 15\n",
      "9 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/5Oig4yqbk5Luwuu3-erome_ss.png\n",
      "predicted number: 9\n",
      "erome.com\n",
      "2024-06-28 03:43:19 [info]: Attempt 1 to process https://erome.com\n",
      "2024-06-28 03:43:20 [info]: Navigated to https://erome.com\n",
      "2024-06-28 03:43:22 [info]: Successfully processed https://erome.com\n",
      "\n",
      "non clickable 8\n",
      "clickable 18\n",
      "cleaned number after removing non clickable elements: 1\n",
      "cleaned number after removing negative classes: 1\n",
      "10 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/5S0ntCXd3jFIzuCE-multistatesociety_ss.png\n",
      "predicted number: 26\n",
      "multistatesociety.in\n",
      "2024-06-28 03:43:25 [info]: Attempt 1 to process https://multistatesociety.in\n",
      "2024-06-28 03:43:27 [info]: Navigated to https://multistatesociety.in\n",
      "2024-06-28 03:43:33 [info]: Successfully processed https://multistatesociety.in\n",
      "\n",
      "non clickable 19\n",
      "clickable 55\n",
      "cleaned number after removing non clickable elements: 7\n",
      "cleaned number after removing negative classes: 6\n",
      "11 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/5fXW9aZnxNP5f4E6-cbsnews_ss.png\n",
      "predicted number: 27\n",
      "cbsnews.com\n",
      "2024-06-28 03:43:36 [info]: Attempt 1 to process https://cbsnews.com\n",
      "2024-06-28 03:43:38 [info]: Navigated to https://cbsnews.com\n",
      "2024-06-28 03:44:28 [info]: Successfully processed https://cbsnews.com\n",
      "\n",
      "non clickable 25\n",
      "clickable 55\n",
      "cleaned number after removing non clickable elements: 2\n",
      "cleaned number after removing negative classes: 1\n",
      "12 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/6NVbPqj48y9ThvwT-readthedocs_ss.png\n",
      "predicted number: 33\n",
      "readthedocs.io\n",
      "2024-06-28 03:44:31 [info]: Attempt 1 to process https://readthedocs.io\n",
      "2024-06-28 03:44:33 [info]: Navigated to https://readthedocs.io\n",
      "2024-06-28 03:44:42 [info]: Successfully processed https://readthedocs.io\n",
      "\n",
      "non clickable 29\n",
      "clickable 25\n",
      "cleaned number after removing non clickable elements: 4\n",
      "cleaned number after removing negative classes: 4\n",
      "13 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/6TEnqJ29XsX8kJpd-games2gether_ss.png\n",
      "predicted number: 42\n",
      "games2gether.com\n",
      "2024-06-28 03:44:45 [info]: Attempt 1 to process https://games2gether.com\n",
      "2024-06-28 03:45:15 [error]: Failed processing https://games2gether.com on attempt 1: page.goto: Timeout 30000ms exceeded.\n",
      "Call log:\n",
      "  \u001b[2m- navigating to \"https://games2gether.com/\", waiting until \"load\"\u001b[22m\n",
      "\n",
      "2024-06-28 03:45:15 [info]: Attempt 2 to process https://games2gether.com\n",
      "2024-06-28 03:45:45 [error]: Failed processing https://games2gether.com on attempt 2: page.goto: Timeout 30000ms exceeded.\n",
      "Call log:\n",
      "  \u001b[2m- navigating to \"https://games2gether.com/\", waiting until \"load\"\u001b[22m\n",
      "\n",
      "2024-06-28 03:45:45 [info]: Attempt 3 to process https://games2gether.com\n",
      "2024-06-28 03:46:15 [error]: Failed processing https://games2gether.com on attempt 3: page.goto: Timeout 30000ms exceeded.\n",
      "Call log:\n",
      "  \u001b[2m- navigating to \"https://games2gether.com/\", waiting until \"load\"\u001b[22m\n",
      "\n",
      "2024-06-28 03:46:15 [error]: Exceeded retry limit for https://games2gether.com\n",
      "\n",
      "cleaned number after removing negative classes: 37\n",
      "14 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/6gFw7bP2szwMmY3G-worldtimebuddy_ss.png\n",
      "predicted number: 31\n",
      "worldtimebuddy.com\n",
      "2024-06-28 03:46:21 [info]: Attempt 1 to process https://worldtimebuddy.com\n",
      "2024-06-28 03:46:22 [info]: Navigated to https://worldtimebuddy.com\n",
      "2024-06-28 03:46:35 [error]: Failed processing https://worldtimebuddy.com on attempt 1: elementHandle.isEnabled: Element is not attached to the DOM\n",
      "Call log:\n",
      "  \u001b[2m- waiting for locator(':scope')\u001b[22m\n",
      "\u001b[2m  -   locator resolved to <script>↵⇆⇆⇆⇆⇆⇆⇆googletag.cmd.push(function() { googletag…</script>\u001b[22m\n",
      "\n",
      "2024-06-28 03:46:35 [info]: Attempt 2 to process https://worldtimebuddy.com\n",
      "2024-06-28 03:46:36 [info]: Navigated to https://worldtimebuddy.com\n",
      "2024-06-28 03:46:48 [error]: Failed processing https://worldtimebuddy.com on attempt 2: elementHandle.isEnabled: Element is not attached to the DOM\n",
      "Call log:\n",
      "  \u001b[2m- waiting for locator(':scope')\u001b[22m\n",
      "\u001b[2m  -   locator resolved to <script>↵⇆⇆⇆⇆⇆⇆⇆googletag.cmd.push(function() { googletag…</script>\u001b[22m\n",
      "\n",
      "2024-06-28 03:46:48 [info]: Attempt 3 to process https://worldtimebuddy.com\n",
      "2024-06-28 03:46:50 [info]: Navigated to https://worldtimebuddy.com\n",
      "2024-06-28 03:47:02 [error]: Failed processing https://worldtimebuddy.com on attempt 3: elementHandle.isEnabled: Element is not attached to the DOM\n",
      "Call log:\n",
      "  \u001b[2m- waiting for locator(':scope')\u001b[22m\n",
      "\u001b[2m  -   locator resolved to <script>↵⇆⇆⇆⇆⇆⇆⇆googletag.cmd.push(function() { googletag…</script>\u001b[22m\n",
      "\n",
      "2024-06-28 03:47:02 [error]: Exceeded retry limit for https://worldtimebuddy.com\n",
      "\n",
      "cleaned number after removing negative classes: 28\n",
      "15 /mnt/nis_lab_research/data/coco_files/og/test/ft_test1_c10/images/70prigfU3y7EidTs-thrivent_ss.png\n",
      "predicted number: 25\n",
      "thrivent.com\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted number:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(data_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotations\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_clickable_elems_only:\n\u001b[0;32m---> 23\u001b[0m     nce_list, ce_bbox_list \u001b[38;5;241m=\u001b[39m \u001b[43mget_non_clickable_elem_ind_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_bbox_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nce_list \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ce_bbox_list \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[29], line 13\u001b[0m, in \u001b[0;36mget_non_clickable_elem_ind_list\u001b[0;34m(img_path, pred_bbox_list)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in master_url_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Get clickable elements for the domain\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m ces \u001b[38;5;241m=\u001b[39m \u001b[43mget_clickable_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ces \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 13\u001b[0m, in \u001b[0;36mget_clickable_elements\u001b[0;34m(domains)\u001b[0m\n\u001b[1;32m     11\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../get_clickable_elems/get_clickable_elems.js\u001b[39m\u001b[38;5;124m'\u001b[39m, url]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mstdout)  \u001b[38;5;66;03m# Print the standard output from the command\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/int_venv/lib/python3.8/subprocess.py:495\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    497\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda3/envs/int_venv/lib/python3.8/subprocess.py:1028\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1028\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/int_venv/lib/python3.8/subprocess.py:1884\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1877\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   1878\u001b[0m                         stdout, stderr,\n\u001b[1;32m   1879\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1880\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   1881\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1882\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1884\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   1887\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/int_venv/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "master_det_dict = []\n",
    "\n",
    "for i, img_path in enumerate(img_path_list[0:25]):\n",
    "\n",
    "    vis_outpath = os.path.join(vis_out_dir, os.path.basename(img_path))\n",
    "\n",
    "    # Creating master dictionary of detected elements\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    pred_out_list = []\n",
    "    for od_pred in obj_det_pred_list:\n",
    "        pred_out_list.append(od_pred(img))\n",
    "    outputs = merge_outputs(pred_out_list)\n",
    "    \n",
    "    print('###############################################################################################')\n",
    "    print(i, img_path)\n",
    "    \n",
    "    data_dict = createDataDict(img_path, outputs)\n",
    "    pred_bbox_list = [ann[\"bbox\"] for ann in data_dict[\"annotations\"]]\n",
    "\n",
    "    print(\"predicted number:\", len(data_dict[\"annotations\"]))\n",
    "\n",
    "    if keep_clickable_elems_only:\n",
    "        nce_list, ce_bbox_list = get_non_clickable_elem_ind_list(img_path, pred_bbox_list)\n",
    "\n",
    "        if nce_list == None and ce_bbox_list == None:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            print('non clickable', len(nce_list))\n",
    "            print('clickable', len(ce_bbox_list))\n",
    "\n",
    "            z_list = ['0' for _ in range(len(ce_bbox_list))]\n",
    "            \n",
    "            draw_bounding_boxes(img_path, ce_bbox_list, z_list, vis_outpath, color='green')\n",
    "\n",
    "            for ind in sorted(nce_list, reverse=True):\n",
    "                data_dict[\"annotations\"].pop(ind)\n",
    "                pred_bbox_list.pop(ind)\n",
    "\n",
    "            print(\"cleaned number after removing non clickable elements:\", len(data_dict[\"annotations\"]))\n",
    "\n",
    "    elem_img_list = process_image(data_dict[\"file_name\"], pred_bbox_list, padding, bg_color, border)\n",
    "    \n",
    "    pred_ids = []\n",
    "    pred_classes = []\n",
    "    remove_list = []\n",
    "    \n",
    "    for j, img in enumerate(elem_img_list):\n",
    "        \n",
    "        img_t = transform(img.convert('RGB')).unsqueeze(0).to('cuda')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = classifier(img_t)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        # OG\n",
    "        # pred_class_id = str(predicted.item() + 1)\n",
    "        pred_class_id = str(predicted.item())\n",
    "        pred_class_name = cats[pred_class_id]\n",
    "        \n",
    "        if remove_neg and pred_class_id == neg_class_id:\n",
    "            remove_list.append(j)\n",
    "\n",
    "        pred_ids.append(pred_class_id)\n",
    "        pred_classes.append(pred_classes)\n",
    "        # data_dict[\"annotations\"][j][\"category_id\"] = int(pred_class_id)\n",
    "        data_dict[\"annotations\"][j][\"category_id\"] = pred_class_name\n",
    "    \n",
    "    if remove_neg and remove_list:\n",
    "         for ind in sorted(remove_list, reverse=True):\n",
    "            data_dict[\"annotations\"].pop(ind)\n",
    "            pred_bbox_list.pop(ind)\n",
    "            pred_ids.pop(ind)\n",
    "            pred_classes.pop(ind)\n",
    "            \n",
    "    print(\"cleaned number after removing negative classes:\", len(data_dict[\"annotations\"]))\n",
    "    \n",
    "    if os.path.exists(vis_outpath):\n",
    "        draw_bounding_boxes(vis_outpath, pred_bbox_list, pred_ids, vis_outpath, color='red')\n",
    "    else:\n",
    "        draw_bounding_boxes(img_path, pred_bbox_list, pred_ids, vis_outpath, color='red')\n",
    "    \n",
    "    master_det_dict.append(data_dict)\n",
    "    \n",
    "res_outpath = os.path.join(res_out_dir, \"results.json\")\n",
    "print(\"writing out results to\", res_outpath)\n",
    "with open(res_outpath, 'w+') as f:\n",
    "    json.dump(master_det_dict, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "int_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
