{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from multiprocessing import Process, Manager\n",
    "import gc\n",
    "from PIL import Image, ImageDraw, ImageFont\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting CUDA devices as visible\n",
    "cuda_devices = \"2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CUDA devices:\n",
      "  0: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "available_devices = [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]\n",
    "print(\"Available CUDA devices:\")\n",
    "for i, device_name in enumerate(available_devices):\n",
    "    print(f\"  {i}: {device_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1594"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soi(str1, start_char, end_char):\n",
    "    str1 = str(str1)\n",
    "    offst = len(start_char)\n",
    "    ind1 = str1.find(start_char)\n",
    "    ind2 = str1.find(end_char)\n",
    "    s_str = str1[ind1+offst:ind2]\n",
    "    return s_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bbox_xywh(b):\n",
    "    x1, y1, x2, y2 = b\n",
    "    x = x1\n",
    "    y = y1\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    return [x, y, w, h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createDataDict (fn, outputs):\n",
    "    img_shape = list(outputs[\"instances\"].image_size)\n",
    "    img_h = int(img_shape[0])\n",
    "    img_w = int(img_shape[1])\n",
    "    ann_list = []\n",
    "\n",
    "    class_list = get_soi(outputs[\"instances\"].pred_classes, \"[\", \"]\").split(\",\")\n",
    "    \n",
    "    if class_list[0] != \"\":\n",
    "\n",
    "        class_list_new = []\n",
    "        for each in class_list:\n",
    "            if each.strip().isdigit():\n",
    "                class_list_new.append(int(each.strip()))\n",
    "            else:\n",
    "                print(f\"Invalid class ID: {each}\")\n",
    "\n",
    "        bbox_list = get_soi(outputs[\"instances\"].pred_boxes, \"[[\", \"]]\").split(\"]\")\n",
    "        bbox_list_new = []\n",
    "        for each in bbox_list:\n",
    "            bbox = re.sub(\"['[,\\n]\", \"\", each).split(\" \")\n",
    "            bbox_new = []\n",
    "            for item in bbox:\n",
    "                if item != \"\":\n",
    "                    bbox_new.append(float(item))\n",
    "            bbox_new = convert_bbox_xywh(bbox_new)\n",
    "            bbox_list_new.append(bbox_new)\n",
    "\n",
    "        for i in range(0, len(class_list)):\n",
    "            # og was \"bbox_mode\": \"<BoxMode.XYWH_ABS: 1>\"\n",
    "            ann_list.append({\"iscrowd\": 0, \"bbox\": bbox_list_new[i], \"category_id\": class_list_new[i], \"bbox_mode\": 0})\n",
    "    \n",
    "    data_dict = {\n",
    "        \"file_name\": fn,\n",
    "        \"height\": img_h,\n",
    "        \"width\": img_w, \n",
    "        \"annotations\": ann_list\n",
    "    }\n",
    " \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(file_path, bounding_box, padding):\n",
    "    \n",
    "    with Image.open(file_path) as img:\n",
    "        \n",
    "        x_min, y_min, width, height = bounding_box\n",
    "\n",
    "        # Calculate padding in pixels\n",
    "        pad_width = int(width * padding)\n",
    "        pad_height = int(height * padding)\n",
    "\n",
    "        # Adjust the bounding box with padding\n",
    "        x_min = max(x_min - pad_width, 0)\n",
    "        y_min = max(y_min - pad_height, 0)\n",
    "        x1 = min(x_min + width + 2 * pad_width, img.width)\n",
    "        y1 = min(y_min + height + 2 * pad_height, img.height)\n",
    "        \n",
    "        cropped_img = img.crop((x_min, y_min, x1, y1))\n",
    "        \n",
    "        return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paste_to_bg(image, background_color, bg_width, bg_height):\n",
    "    \n",
    "    # Create a new image with the specified background color and dimensions\n",
    "    background = Image.new('RGB', (bg_width, bg_height), background_color)\n",
    "\n",
    "    # Calculate the position to paste the image so it's centered\n",
    "    x = (bg_width - image.width) // 2\n",
    "    y = (bg_height - image.height) // 2\n",
    "\n",
    "    # Paste the image onto the background\n",
    "    background.paste(image, (x, y), image if image.mode == 'RGBA' else None)\n",
    "\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_ar_lock(img, target_size):\n",
    "\n",
    "    original_width, original_height = img.size\n",
    "    target_width, target_height = target_size\n",
    "\n",
    "    # Calculate scaling factor\n",
    "    scaling_factor = min(target_width / original_width, target_height / original_height)\n",
    "\n",
    "    # Calculate new dimensions\n",
    "    new_width = max(int(original_width * scaling_factor), 1)\n",
    "    new_height = max(int(original_height * scaling_factor), 1)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = img.resize((new_width, new_height))\n",
    "\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rand_str(length):\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    random_string = ''.join(random.choice(characters) for i in range(length))\n",
    "    return random_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img_fp, bbox_list, padding, bg_color, border):\n",
    "    \n",
    "    # Create an empty list to store processed images\n",
    "    processed_images = []\n",
    "\n",
    "    for j, bbox in enumerate(bbox_list):\n",
    "\n",
    "        try:\n",
    "            elem_img = crop_image(img_fp, bbox, padding)\n",
    "            e_w = elem_img.size[0]\n",
    "            e_h = elem_img.size[1]\n",
    "\n",
    "            if e_w < e_h:\n",
    "                elem_img = paste_to_bg(elem_img, bg_color, e_h + border, e_h + border)\n",
    "            elif e_w > e_h:\n",
    "                elem_img = paste_to_bg(elem_img, bg_color, e_w + border, e_w + border)\n",
    "                \n",
    "            # elem_img = transform(elem_img)\n",
    "            processed_images.append(elem_img)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(img_fp)\n",
    "            print(e)\n",
    "\n",
    "    # Return the list of processed images\n",
    "    return processed_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(image_path, bbox_list, label_list, output_path):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Load a font\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    # Draw bounding boxes and labels\n",
    "    for bbox, label in zip(bbox_list, label_list):\n",
    "        x, y, w, h = bbox\n",
    "        draw.rectangle([x, y, x+w, y+h], outline=\"red\")\n",
    "        draw.text((x, y), label, fill=\"red\", font=font)\n",
    "\n",
    "    # Save the new image\n",
    "    image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = \"/mnt/nis_lab_research/data/coco_files/test/test1\"\n",
    "res_out_dir = \"./res_out_dir\"\n",
    "vis_out_dir = \"./res_out_dir/vis\"\n",
    "cat_path = \"/mnt/nis_lab_research/data/elem_cat/cat_neg_27.json\"\n",
    "bg_color = \"white\"\n",
    "padding = 0.05\n",
    "border = 0\n",
    "remove_neg = True\n",
    "neg_class_name = \"Random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(res_out_dir):\n",
    "    shutil.rmtree(res_out_dir)\n",
    "os.makedirs(vis_out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logger()\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "# cfg.MODEL.WEIGHTS = os.path.join(\"/home/dtron2_user/ls_dtron2_full/model/output\", \"model_final.pth\")\n",
    "cfg.MODEL.WEIGHTS = os.path.join(\"/mnt/nis_lab_research/data/pth\", \"far_shah_b1-b5_b8_train_EOI.pth\")\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_pth = \"/mnt/nis_lab_research/data/pth/far_shah_b1-b5_b8_train_neg_ep25.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_list = [os.path.join(in_dir, \"images\", img_path) for img_path in os.listdir(os.path.join(in_dir, \"images\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/11 23:28:05 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /mnt/nis_lab_research/data/pth/far_shah_b1-b5_b8_train_EOI.pth ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=27, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_det_pred = DefaultPredictor(cfg)\n",
    "classifier = torch.load(classifier_pth)\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cat_path, 'r') as f:\n",
    "    cats = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_class_id = \"\"\n",
    "\n",
    "for key, value in cats.items():\n",
    "    if value == neg_class_name:\n",
    "        neg_class_id = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /mnt/nis_lab_research/data/coco_files/test/test1/images/0mpdgmPb3OKP7GwG-investorideas_ss.png\n",
      "predicted number: 42\n",
      "cleaned number: 40\n",
      "1 /mnt/nis_lab_research/data/coco_files/test/test1/images/hLv3ijm31G1URmH6-navyfederal_ss.png\n",
      "predicted number: 31\n",
      "cleaned number: 30\n",
      "2 /mnt/nis_lab_research/data/coco_files/test/test1/images/L9oDbA9sni99lgdr-brightspace_ss.png\n",
      "predicted number: 25\n",
      "cleaned number: 24\n",
      "3 /mnt/nis_lab_research/data/coco_files/test/test1/images/tof4mTWQkTh1zRSe-oasiscannabis_ss.png\n",
      "predicted number: 12\n",
      "cleaned number: 12\n",
      "4 /mnt/nis_lab_research/data/coco_files/test/test1/images/QNdJuEakVFnJTMgq-uptodown_ss.png\n",
      "predicted number: 24\n",
      "cleaned number: 23\n",
      "5 /mnt/nis_lab_research/data/coco_files/test/test1/images/LgTCcgKP5TdxPSX4-gettyimages_ss.png\n",
      "predicted number: 32\n",
      "cleaned number: 29\n",
      "6 /mnt/nis_lab_research/data/coco_files/test/test1/images/b12AVGFM3lA4v2C0-shortcutsolutions_ss.png\n",
      "predicted number: 21\n",
      "cleaned number: 21\n",
      "7 /mnt/nis_lab_research/data/coco_files/test/test1/images/XzAharZEg6KpqIzd-projectseven_ss.png\n",
      "predicted number: 7\n",
      "cleaned number: 7\n",
      "8 /mnt/nis_lab_research/data/coco_files/test/test1/images/0OIksf6yJXACtA9I-legalzoom_ss.png\n",
      "predicted number: 19\n",
      "cleaned number: 18\n",
      "9 /mnt/nis_lab_research/data/coco_files/test/test1/images/EuI0U0g2CmNB6scH-yabbycasino_ss.png\n",
      "predicted number: 26\n",
      "cleaned number: 23\n",
      "10 /mnt/nis_lab_research/data/coco_files/test/test1/images/fKqL3lpMutF0P281-palmplaystore_ss.png\n",
      "predicted number: 10\n",
      "cleaned number: 10\n",
      "11 /mnt/nis_lab_research/data/coco_files/test/test1/images/68O8MADx81sNrUrH-firsttactical_ss.png\n",
      "predicted number: 18\n",
      "cleaned number: 18\n",
      "12 /mnt/nis_lab_research/data/coco_files/test/test1/images/5boADp7PkvOokhes-michaelschenkerhimself_ss.png\n",
      "predicted number: 11\n",
      "cleaned number: 11\n",
      "13 /mnt/nis_lab_research/data/coco_files/test/test1/images/5dfgMzx6cj57loMN-em_ss.png\n",
      "predicted number: 47\n",
      "cleaned number: 47\n",
      "14 /mnt/nis_lab_research/data/coco_files/test/test1/images/z4tCvUu9nihse0CN-blackboardjob_ss.png\n",
      "predicted number: 8\n",
      "cleaned number: 8\n",
      "15 /mnt/nis_lab_research/data/coco_files/test/test1/images/AhdC8513hQv3YrAT-biblegateway_ss.png\n",
      "predicted number: 39\n",
      "cleaned number: 38\n",
      "16 /mnt/nis_lab_research/data/coco_files/test/test1/images/oNU8xHRljgwbAHqc-crypto-economy_ss.png\n",
      "predicted number: 21\n",
      "cleaned number: 18\n",
      "17 /mnt/nis_lab_research/data/coco_files/test/test1/images/tLTU36rFU6ZpoNoi-twistedmexi_ss.png\n",
      "predicted number: 28\n",
      "cleaned number: 28\n",
      "18 /mnt/nis_lab_research/data/coco_files/test/test1/images/mce3mT9XDlRPwTt1-gaytorrent_ss.png\n",
      "predicted number: 8\n",
      "cleaned number: 8\n",
      "19 /mnt/nis_lab_research/data/coco_files/test/test1/images/Tcw46geZluDXqvyQ-odva_ss.png\n",
      "predicted number: 15\n",
      "cleaned number: 15\n",
      "20 /mnt/nis_lab_research/data/coco_files/test/test1/images/TqYc8zUrx4DjkAEq-site44_ss.png\n",
      "predicted number: 13\n",
      "cleaned number: 10\n",
      "21 /mnt/nis_lab_research/data/coco_files/test/test1/images/1Rk264flsJusg9Jg-technicalgaurav_ss.png\n",
      "predicted number: 26\n",
      "cleaned number: 23\n",
      "22 /mnt/nis_lab_research/data/coco_files/test/test1/images/QZ15ZiP2w6a1Bxis-nodejs_ss.png\n",
      "predicted number: 14\n",
      "cleaned number: 14\n",
      "23 /mnt/nis_lab_research/data/coco_files/test/test1/images/pWKMAFuVjgANeoBT-ouo_ss.png\n",
      "predicted number: 5\n",
      "cleaned number: 5\n",
      "24 /mnt/nis_lab_research/data/coco_files/test/test1/images/lFwWj6X5TD5lDUxy-thenewsgod_ss.png\n",
      "predicted number: 36\n",
      "cleaned number: 36\n",
      "25 /mnt/nis_lab_research/data/coco_files/test/test1/images/OvzuzAHWdefEjdZP-prednisolone_ss.png\n",
      "predicted number: 12\n",
      "cleaned number: 10\n",
      "26 /mnt/nis_lab_research/data/coco_files/test/test1/images/QzIrE20IDb1dbKIc-aims-communities_ss.png\n",
      "predicted number: 13\n",
      "cleaned number: 13\n",
      "27 /mnt/nis_lab_research/data/coco_files/test/test1/images/d4Vy5isH6dF6dWzW-centrebet_ss.png\n",
      "predicted number: 20\n",
      "cleaned number: 20\n",
      "28 /mnt/nis_lab_research/data/coco_files/test/test1/images/zSuOktSKX7hVc4v3-madelinetosh_ss.png\n",
      "predicted number: 19\n",
      "cleaned number: 17\n",
      "29 /mnt/nis_lab_research/data/coco_files/test/test1/images/75PoBRweHOvPeU1n-duosecurity_ss.png\n",
      "predicted number: 26\n",
      "cleaned number: 25\n",
      "30 /mnt/nis_lab_research/data/coco_files/test/test1/images/w95vKez2Eg4la2HT-betches_ss.png\n",
      "predicted number: 39\n",
      "cleaned number: 37\n",
      "31 /mnt/nis_lab_research/data/coco_files/test/test1/images/tFAZVKgxLm5pmRWs-thegeschaft_ss.png\n",
      "predicted number: 10\n",
      "cleaned number: 10\n",
      "32 /mnt/nis_lab_research/data/coco_files/test/test1/images/p2SowIsNKb6Opm2E-photowall_ss.png\n",
      "predicted number: 28\n",
      "cleaned number: 26\n",
      "33 /mnt/nis_lab_research/data/coco_files/test/test1/images/S6SlsipLvSWUklfV-newvisions_ss.png\n",
      "predicted number: 27\n",
      "cleaned number: 27\n",
      "34 /mnt/nis_lab_research/data/coco_files/test/test1/images/zvcHOYASiLtPFpsc-rodgab_ss.png\n",
      "predicted number: 15\n",
      "cleaned number: 15\n",
      "35 /mnt/nis_lab_research/data/coco_files/test/test1/images/fG5R7xo40ZqHmcMC-henryharvin_ss.png\n",
      "predicted number: 20\n",
      "cleaned number: 20\n",
      "36 /mnt/nis_lab_research/data/coco_files/test/test1/images/pZRIrXgH8DFEF45Q-watchguard_ss.png\n",
      "predicted number: 27\n",
      "cleaned number: 25\n",
      "37 /mnt/nis_lab_research/data/coco_files/test/test1/images/ptodWPlZ6mTGRapk-ernest_ss.png\n",
      "predicted number: 7\n",
      "cleaned number: 6\n",
      "38 /mnt/nis_lab_research/data/coco_files/test/test1/images/R1HUIiEtlr30eXg6-b2bmarketing_ss.png\n",
      "predicted number: 25\n",
      "cleaned number: 25\n",
      "39 /mnt/nis_lab_research/data/coco_files/test/test1/images/yeBtf8b82y4mA0Bs-kamleshyadav_ss.png\n",
      "predicted number: 54\n",
      "cleaned number: 53\n",
      "40 /mnt/nis_lab_research/data/coco_files/test/test1/images/oh1FJe2dfdJdFiXg-membean_ss.png\n",
      "predicted number: 17\n",
      "cleaned number: 15\n",
      "41 /mnt/nis_lab_research/data/coco_files/test/test1/images/XqYQ7qWfDWhNPrJe-rushmorelm_ss.png\n",
      "predicted number: 8\n",
      "cleaned number: 8\n",
      "42 /mnt/nis_lab_research/data/coco_files/test/test1/images/zJn4oma1nSLFgk2n-uateka_ss.png\n",
      "predicted number: 31\n",
      "cleaned number: 27\n",
      "43 /mnt/nis_lab_research/data/coco_files/test/test1/images/PqYXAZ9HCb4czSDA-shopify_ss.png\n",
      "predicted number: 11\n",
      "cleaned number: 10\n",
      "44 /mnt/nis_lab_research/data/coco_files/test/test1/images/51Wgaq4GYYvAZH1H-ipcc_ss.png\n",
      "predicted number: 42\n",
      "cleaned number: 40\n",
      "45 /mnt/nis_lab_research/data/coco_files/test/test1/images/5uBsPCCs5DBtpvq0-psu_ss.png\n",
      "predicted number: 20\n",
      "cleaned number: 20\n",
      "46 /mnt/nis_lab_research/data/coco_files/test/test1/images/lJq2cMsno78Co9LJ-bitsysbrainfood_ss.png\n",
      "predicted number: 13\n",
      "cleaned number: 13\n",
      "47 /mnt/nis_lab_research/data/coco_files/test/test1/images/L9mvrtbV8iN3dpnz-clutchy_ss.png\n",
      "predicted number: 26\n",
      "cleaned number: 24\n",
      "48 /mnt/nis_lab_research/data/coco_files/test/test1/images/yWDMfFF1CRhmjnT3-yoteathletics_ss.png\n",
      "predicted number: 32\n",
      "cleaned number: 28\n",
      "49 /mnt/nis_lab_research/data/coco_files/test/test1/images/mvMrbAN4YcsOqKnf-adr_ss.png\n",
      "predicted number: 51\n",
      "cleaned number: 50\n",
      "50 /mnt/nis_lab_research/data/coco_files/test/test1/images/GPNnwNGJ9DydyxpO-duke_ss.png\n",
      "predicted number: 21\n",
      "cleaned number: 20\n",
      "51 /mnt/nis_lab_research/data/coco_files/test/test1/images/OREwbBWyTcmCdpD8-golden-road_ss.png\n",
      "predicted number: 20\n",
      "cleaned number: 20\n",
      "52 /mnt/nis_lab_research/data/coco_files/test/test1/images/zvMLt7je4ErY7HwR-ria-news_ss.png\n",
      "predicted number: 14\n",
      "cleaned number: 14\n",
      "53 /mnt/nis_lab_research/data/coco_files/test/test1/images/FzwcfJHvhY7NWzgs-makebelieveco_ss.png\n",
      "predicted number: 28\n",
      "cleaned number: 26\n",
      "54 /mnt/nis_lab_research/data/coco_files/test/test1/images/QpRcDgQ1Eq2MbeFC-dogsimity_ss.png\n",
      "predicted number: 17\n",
      "cleaned number: 17\n",
      "55 /mnt/nis_lab_research/data/coco_files/test/test1/images/Ut7KCPnQhLthp0RW-lifewire_ss.png\n",
      "predicted number: 29\n",
      "cleaned number: 27\n",
      "56 /mnt/nis_lab_research/data/coco_files/test/test1/images/tXUCtYfbnmpL8epC-propertywala_ss.png\n",
      "predicted number: 8\n",
      "cleaned number: 3\n",
      "57 /mnt/nis_lab_research/data/coco_files/test/test1/images/MtkJC8YU2AMBodgL-embark-studios_ss.png\n",
      "predicted number: 13\n",
      "cleaned number: 13\n",
      "58 /mnt/nis_lab_research/data/coco_files/test/test1/images/ORwrbnhoFWRdPieY-avg_ss.png\n",
      "predicted number: 43\n",
      "cleaned number: 42\n",
      "59 /mnt/nis_lab_research/data/coco_files/test/test1/images/3kSoTgqwTtdLPORy-ecpplatform_ss.png\n",
      "predicted number: 12\n",
      "cleaned number: 12\n",
      "60 /mnt/nis_lab_research/data/coco_files/test/test1/images/ceVOTZ0RRVRteAg5-gwdocs_ss.png\n",
      "predicted number: 27\n",
      "cleaned number: 27\n",
      "61 /mnt/nis_lab_research/data/coco_files/test/test1/images/203FEtzEOm7dZ8Sz-dedicatedcore_ss.png\n",
      "predicted number: 30\n",
      "cleaned number: 30\n",
      "62 /mnt/nis_lab_research/data/coco_files/test/test1/images/Tlytmzuyou0THGI1-cgtrader_ss.png\n",
      "predicted number: 32\n",
      "cleaned number: 32\n",
      "63 /mnt/nis_lab_research/data/coco_files/test/test1/images/sCxqqLhpmlV4Sq2X-nextlevelurgentcare_ss.png\n",
      "predicted number: 25\n",
      "cleaned number: 25\n",
      "64 /mnt/nis_lab_research/data/coco_files/test/test1/images/ywBn0xghn3WcSMAw-wpengine_ss.png\n",
      "predicted number: 37\n",
      "cleaned number: 36\n",
      "65 /mnt/nis_lab_research/data/coco_files/test/test1/images/NhQGolKrlBsuozDX-nasoya_ss.png\n",
      "predicted number: 13\n",
      "cleaned number: 11\n",
      "66 /mnt/nis_lab_research/data/coco_files/test/test1/images/7K8DkA2Br5gpmbku-kartagov_ss.png\n",
      "predicted number: 9\n",
      "cleaned number: 9\n",
      "67 /mnt/nis_lab_research/data/coco_files/test/test1/images/mfLBFfBkq2S7hCGi-thedeaconsbench_ss.png\n",
      "predicted number: 14\n",
      "cleaned number: 13\n",
      "68 /mnt/nis_lab_research/data/coco_files/test/test1/images/1lO4s2Zt0zTFtW3U-amraandelma_ss.png\n",
      "predicted number: 18\n",
      "cleaned number: 18\n",
      "69 /mnt/nis_lab_research/data/coco_files/test/test1/images/jaqGt2ca42EFsexz-birdever_ss.png\n",
      "predicted number: 14\n",
      "cleaned number: 12\n",
      "70 /mnt/nis_lab_research/data/coco_files/test/test1/images/c5rfWS6qR8UwzHcs-filepress_ss.png\n",
      "predicted number: 9\n",
      "cleaned number: 9\n",
      "71 /mnt/nis_lab_research/data/coco_files/test/test1/images/9PBztKhGugkG9qED-windows11tools_ss.png\n",
      "predicted number: 23\n",
      "cleaned number: 23\n",
      "72 /mnt/nis_lab_research/data/coco_files/test/test1/images/OUTKuwrroO01X3yP-corebook_ss.png\n",
      "predicted number: 15\n",
      "cleaned number: 15\n",
      "73 /mnt/nis_lab_research/data/coco_files/test/test1/images/B8vxnIw90tC2eoav-richardharrislaw_ss.png\n",
      "predicted number: 29\n",
      "cleaned number: 27\n",
      "74 /mnt/nis_lab_research/data/coco_files/test/test1/images/9iwsXaOHCQGoFO7J-medlineplus_ss.png\n",
      "predicted number: 14\n",
      "cleaned number: 14\n",
      "75 /mnt/nis_lab_research/data/coco_files/test/test1/images/gANuku69CKhwGhcw-topnotchdezigns_ss.png\n",
      "predicted number: 10\n",
      "cleaned number: 9\n",
      "76 /mnt/nis_lab_research/data/coco_files/test/test1/images/8tavdem92XOxpUDE-whattheythink_ss.png\n",
      "predicted number: 32\n",
      "cleaned number: 32\n",
      "77 /mnt/nis_lab_research/data/coco_files/test/test1/images/hHVBOAaEuHFjAU1y-uca_ss.png\n",
      "predicted number: 25\n",
      "cleaned number: 25\n",
      "78 /mnt/nis_lab_research/data/coco_files/test/test1/images/421hNOXB9gzopPqQ-gta-objects_ss.png\n",
      "predicted number: 19\n",
      "cleaned number: 18\n",
      "79 /mnt/nis_lab_research/data/coco_files/test/test1/images/qpEHO3Vi2lARSx6v-fs19mods_ss.png\n",
      "predicted number: 20\n",
      "cleaned number: 18\n",
      "80 /mnt/nis_lab_research/data/coco_files/test/test1/images/RdWmshT5KifNvM37-foureyes_ss.png\n",
      "predicted number: 31\n",
      "cleaned number: 31\n",
      "81 /mnt/nis_lab_research/data/coco_files/test/test1/images/J0XY909gBZa6nutK-realcomm_ss.png\n",
      "predicted number: 20\n",
      "cleaned number: 20\n",
      "82 /mnt/nis_lab_research/data/coco_files/test/test1/images/yEWWVVj5OI2QcSAL-autoblow_ss.png\n",
      "predicted number: 11\n",
      "cleaned number: 11\n",
      "83 /mnt/nis_lab_research/data/coco_files/test/test1/images/rFEzNSbFKFcGeSyW-desertcart_ss.png\n",
      "predicted number: 14\n",
      "cleaned number: 14\n",
      "84 /mnt/nis_lab_research/data/coco_files/test/test1/images/QdJg6gPyb9ay6eF7-credential_ss.png\n",
      "predicted number: 16\n",
      "cleaned number: 15\n",
      "85 /mnt/nis_lab_research/data/coco_files/test/test1/images/gSjqkKalye9P58rc-furniturebox_ss.png\n",
      "predicted number: 22\n",
      "cleaned number: 22\n",
      "86 /mnt/nis_lab_research/data/coco_files/test/test1/images/j0OhcAsN5sXJq0kN-simbecorion_ss.png\n",
      "predicted number: 24\n",
      "cleaned number: 23\n",
      "87 /mnt/nis_lab_research/data/coco_files/test/test1/images/voOWFiDkie0IZnVj-newslake_ss.png\n",
      "predicted number: 20\n",
      "cleaned number: 20\n",
      "88 /mnt/nis_lab_research/data/coco_files/test/test1/images/lFHP7Sgya57dePEp-amatic_ss.png\n",
      "predicted number: 30\n",
      "cleaned number: 22\n",
      "89 /mnt/nis_lab_research/data/coco_files/test/test1/images/xfiZJFRG1ziJhL45-dordt_ss.png\n",
      "predicted number: 8\n",
      "cleaned number: 8\n",
      "90 /mnt/nis_lab_research/data/coco_files/test/test1/images/sG6sD6hONYSCfJcO-centerforoffshoresafety_ss.png\n",
      "predicted number: 19\n",
      "cleaned number: 18\n",
      "91 /mnt/nis_lab_research/data/coco_files/test/test1/images/voQEJeySdwE7xm7C-1800accountant_ss.png\n",
      "predicted number: 22\n",
      "cleaned number: 22\n",
      "92 /mnt/nis_lab_research/data/coco_files/test/test1/images/aGRG9H0oPiHGLDEA-dognutrition_ss.png\n",
      "predicted number: 23\n",
      "cleaned number: 20\n",
      "93 /mnt/nis_lab_research/data/coco_files/test/test1/images/5nKtKAIuJS7qF9jc-ip2location_ss.png\n",
      "predicted number: 26\n",
      "cleaned number: 26\n",
      "94 /mnt/nis_lab_research/data/coco_files/test/test1/images/35feHipH7TOqtdIT-telire_ss.png\n",
      "predicted number: 26\n",
      "cleaned number: 26\n",
      "95 /mnt/nis_lab_research/data/coco_files/test/test1/images/rzKmhNVwwnNJfYO0-findhussies_ss.png\n",
      "predicted number: 34\n",
      "cleaned number: 33\n",
      "96 /mnt/nis_lab_research/data/coco_files/test/test1/images/Z7aWEqOxUByGAyCF-lesbrown_ss.png\n",
      "predicted number: 19\n",
      "cleaned number: 19\n",
      "97 /mnt/nis_lab_research/data/coco_files/test/test1/images/jIDRchjfsMVN84Md-noursefarms_ss.png\n",
      "predicted number: 17\n",
      "cleaned number: 17\n",
      "98 /mnt/nis_lab_research/data/coco_files/test/test1/images/HwAFDBBbkgkpziTK-gameyum_ss.png\n",
      "predicted number: 19\n",
      "cleaned number: 15\n",
      "99 /mnt/nis_lab_research/data/coco_files/test/test1/images/zGC42Fl5osvIaHh7-jcs_ss.png\n",
      "predicted number: 19\n",
      "cleaned number: 19\n",
      "writing out results to ./res_out_dir/results.json\n"
     ]
    }
   ],
   "source": [
    "master_dict = []\n",
    "\n",
    "for i, img_path in enumerate(img_path_list):\n",
    "    # Creating master dictionary of detected elements\n",
    "    img = cv2.imread(img_path)\n",
    "    outputs = obj_det_pred(img)\n",
    "    \n",
    "    print(i, img_path)\n",
    "    \n",
    "    data_dict = createDataDict(img_path, outputs)\n",
    "    bbox_list = [ann[\"bbox\"] for ann in data_dict[\"annotations\"]]\n",
    "    elem_img_list = process_image(data_dict[\"file_name\"], bbox_list, padding, bg_color, border)\n",
    "    \n",
    "    pred_ids = []\n",
    "    pred_classes = []\n",
    "    remove_list = []\n",
    "    \n",
    "    for j, img in enumerate(elem_img_list):\n",
    "        \n",
    "        img_t = transform(img.convert('RGB')).unsqueeze(0).to('cuda')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = classifier(img_t)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        pred_class_id = str(predicted.item() + 1)\n",
    "        pred_class_name = cats[pred_class_id]\n",
    "        \n",
    "        if remove_neg and pred_class_id == neg_class_id:\n",
    "            remove_list.append(j)\n",
    "\n",
    "        pred_ids.append(pred_class_id)\n",
    "        pred_classes.append(pred_classes)\n",
    "        # data_dict[\"annotations\"][j][\"category_id\"] = int(pred_class_id)\n",
    "        data_dict[\"annotations\"][j][\"category_id\"] = pred_class_name\n",
    "        \n",
    "    print(\"predicted number:\", len(data_dict[\"annotations\"]))\n",
    "    \n",
    "    if remove_neg and remove_list:\n",
    "         for ind in sorted(remove_list, reverse=True):\n",
    "            data_dict[\"annotations\"].pop(ind)\n",
    "            bbox_list.pop(ind)\n",
    "            pred_ids.pop(ind)\n",
    "            pred_classes.pop(ind)\n",
    "            \n",
    "    print(\"cleaned number:\", len(data_dict[\"annotations\"]))\n",
    "        \n",
    "    vis_outpath = os.path.join(vis_out_dir, os.path.basename(img_path))\n",
    "    draw_bounding_boxes(img_path, bbox_list, pred_ids, vis_outpath)\n",
    "    master_dict.append(data_dict)\n",
    "    \n",
    "res_outpath = os.path.join(res_out_dir, \"results.json\")\n",
    "print(\"writing out results to\", res_outpath)\n",
    "with open(res_outpath, 'w+') as f:\n",
    "    json.dump(master_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "int_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
