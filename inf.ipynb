{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from multiprocessing import Process, Manager\n",
    "import gc\n",
    "from PIL import Image, ImageDraw, ImageFont\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting CUDA devices as visible\n",
    "cuda_devices = \"2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CUDA devices:\n",
      "  0: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "available_devices = [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]\n",
    "print(\"Available CUDA devices:\")\n",
    "for i, device_name in enumerate(available_devices):\n",
    "    print(f\"  {i}: {device_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soi(str1, start_char, end_char):\n",
    "    str1 = str(str1)\n",
    "    offst = len(start_char)\n",
    "    ind1 = str1.find(start_char)\n",
    "    ind2 = str1.find(end_char)\n",
    "    s_str = str1[ind1+offst:ind2]\n",
    "    return s_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bbox_xywh(b):\n",
    "    x1, y1, x2, y2 = b\n",
    "    x = x1\n",
    "    y = y1\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    return [x, y, w, h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createDataDict (fn, outputs):\n",
    "    img_shape = list(outputs[\"instances\"].image_size)\n",
    "    img_h = int(img_shape[0])\n",
    "    img_w = int(img_shape[1])\n",
    "    ann_list = []\n",
    "\n",
    "    class_list = get_soi(outputs[\"instances\"].pred_classes, \"[\", \"]\").split(\",\")\n",
    "    \n",
    "    if class_list[0] != \"\":\n",
    "\n",
    "        class_list_new = []\n",
    "        for each in class_list:\n",
    "            if each.strip().isdigit():\n",
    "                class_list_new.append(int(each.strip()))\n",
    "            else:\n",
    "                print(f\"Invalid class ID: {each}\")\n",
    "\n",
    "        bbox_list = get_soi(outputs[\"instances\"].pred_boxes, \"[[\", \"]]\").split(\"]\")\n",
    "        bbox_list_new = []\n",
    "        for each in bbox_list:\n",
    "            bbox = re.sub(\"['[,\\n]\", \"\", each).split(\" \")\n",
    "            bbox_new = []\n",
    "            for item in bbox:\n",
    "                if item != \"\":\n",
    "                    bbox_new.append(float(item))\n",
    "            bbox_new = convert_bbox_xywh(bbox_new)\n",
    "            bbox_list_new.append(bbox_new)\n",
    "\n",
    "        for i in range(0, len(class_list)):\n",
    "            # og was \"bbox_mode\": \"<BoxMode.XYWH_ABS: 1>\"\n",
    "            ann_list.append({\"iscrowd\": 0, \"bbox\": bbox_list_new[i], \"category_id\": class_list_new[i], \"bbox_mode\": 0})\n",
    "    \n",
    "    data_dict = {\n",
    "        \"file_name\": fn,\n",
    "        \"height\": img_h,\n",
    "        \"width\": img_w, \n",
    "        \"annotations\": ann_list\n",
    "    }\n",
    " \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(file_path, bounding_box, padding):\n",
    "    \n",
    "    with Image.open(file_path) as img:\n",
    "        \n",
    "        x_min, y_min, width, height = bounding_box\n",
    "\n",
    "        # Calculate padding in pixels\n",
    "        pad_width = int(width * padding)\n",
    "        pad_height = int(height * padding)\n",
    "\n",
    "        # Adjust the bounding box with padding\n",
    "        x_min = max(x_min - pad_width, 0)\n",
    "        y_min = max(y_min - pad_height, 0)\n",
    "        x1 = min(x_min + width + 2 * pad_width, img.width)\n",
    "        y1 = min(y_min + height + 2 * pad_height, img.height)\n",
    "        \n",
    "        cropped_img = img.crop((x_min, y_min, x1, y1))\n",
    "        \n",
    "        return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paste_to_bg(image, background_color, bg_width, bg_height):\n",
    "    \n",
    "    # Create a new image with the specified background color and dimensions\n",
    "    background = Image.new('RGB', (bg_width, bg_height), background_color)\n",
    "\n",
    "    # Calculate the position to paste the image so it's centered\n",
    "    x = (bg_width - image.width) // 2\n",
    "    y = (bg_height - image.height) // 2\n",
    "\n",
    "    # Paste the image onto the background\n",
    "    background.paste(image, (x, y), image if image.mode == 'RGBA' else None)\n",
    "\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_ar_lock(img, target_size):\n",
    "\n",
    "    original_width, original_height = img.size\n",
    "    target_width, target_height = target_size\n",
    "\n",
    "    # Calculate scaling factor\n",
    "    scaling_factor = min(target_width / original_width, target_height / original_height)\n",
    "\n",
    "    # Calculate new dimensions\n",
    "    new_width = max(int(original_width * scaling_factor), 1)\n",
    "    new_height = max(int(original_height * scaling_factor), 1)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = img.resize((new_width, new_height))\n",
    "\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rand_str(length):\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    random_string = ''.join(random.choice(characters) for i in range(length))\n",
    "    return random_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img_fp, bbox_list, padding, bg_color, border):\n",
    "    \n",
    "    # Create an empty list to store processed images\n",
    "    processed_images = []\n",
    "\n",
    "    for j, bbox in enumerate(bbox_list):\n",
    "\n",
    "        try:\n",
    "            elem_img = crop_image(img_fp, bbox, padding)\n",
    "            e_w = elem_img.size[0]\n",
    "            e_h = elem_img.size[1]\n",
    "\n",
    "            if e_w < e_h:\n",
    "                elem_img = paste_to_bg(elem_img, bg_color, e_h + border, e_h + border)\n",
    "            elif e_w > e_h:\n",
    "                elem_img = paste_to_bg(elem_img, bg_color, e_w + border, e_w + border)\n",
    "                \n",
    "            # elem_img = transform(elem_img)\n",
    "            processed_images.append(elem_img)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(img_fp)\n",
    "            print(e)\n",
    "\n",
    "    # Return the list of processed images\n",
    "    return processed_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(image_path, bbox_list, label_list, output_path):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Load a font\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    # Draw bounding boxes and labels\n",
    "    for bbox, label in zip(bbox_list, label_list):\n",
    "        x, y, w, h = bbox\n",
    "        draw.rectangle([x, y, x+w, y+h], outline=\"red\")\n",
    "        draw.text((x, y), label, fill=\"red\", font=font)\n",
    "\n",
    "    # Save the new image\n",
    "    image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = \"/mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21\"\n",
    "vis_out_dir = \"./vis_out_dir\"\n",
    "res_out_dir = \"./res_out_dir\"\n",
    "cat_path = \"/mnt/nis_lab_research/data/elem_cat/cat_neg_27.json\"\n",
    "bg_color = \"white\"\n",
    "padding = 0.05\n",
    "border = 0\n",
    "remove_neg = True\n",
    "neg_class_name = \"Random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(vis_out_dir):\n",
    "    shutil.rmtree(vis_out_dir)\n",
    "if os.path.exists(res_out_dir):\n",
    "    shutil.rmtree(res_out_dir)\n",
    "os.makedirs(vis_out_dir)\n",
    "os.makedirs(res_out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logger()\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "# cfg.MODEL.WEIGHTS = os.path.join(\"/home/dtron2_user/ls_dtron2_full/model/output\", \"model_final.pth\")\n",
    "cfg.MODEL.WEIGHTS = os.path.join(\"/mnt/nis_lab_research/data/pth\", \"far_shah_b1-b5_b8_train_EOI.pth\")\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_pth = \"/mnt/nis_lab_research/data/pth/far_shah_b1-b5_b8_train_neg_ep25.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_list = [os.path.join(in_dir, \"images\", img_path) for img_path in os.listdir(os.path.join(in_dir, \"images\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/11 17:31:08 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /mnt/nis_lab_research/data/pth/far_shah_b1-b5_b8_train_EOI.pth ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=27, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_det_pred = DefaultPredictor(cfg)\n",
    "classifier = torch.load(classifier_pth)\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cat_path, 'r') as f:\n",
    "    cats = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_class_id = \"\"\n",
    "\n",
    "for key, value in cats.items():\n",
    "    if value == neg_class_name:\n",
    "        neg_class_id = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/wfOwvVjZmow18W3D-openstreetmap_ss.png\n",
      "predicted number: 28\n",
      "cleaned number: 27\n",
      "1 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/DTsJuD8QKOmpTnMC-fb_ss.png\n",
      "predicted number: 9\n",
      "cleaned number: 9\n",
      "2 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/rQiYVQ9T6dwfcP8q-stripe_ss.png\n",
      "predicted number: 40\n",
      "cleaned number: 37\n",
      "3 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/IoJhmGSAYCWN0Hx0-sedo_ss.png\n",
      "predicted number: 48\n",
      "cleaned number: 47\n",
      "4 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/8Sa7k44tMYsfCjp7-myfritz_ss.png\n",
      "predicted number: 14\n",
      "cleaned number: 13\n",
      "5 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/a8iNfAw7DRacMihD-utexas_ss.png\n",
      "predicted number: 27\n",
      "cleaned number: 27\n",
      "6 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/BMUWN58kNd1PllJH-craigslist_ss.png\n",
      "predicted number: 23\n",
      "cleaned number: 23\n",
      "7 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/4z9bu9CCuSM0oAra-harvard_ss.png\n",
      "predicted number: 8\n",
      "cleaned number: 6\n",
      "8 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/6xYN6b8paddlQk86-okta_ss.png\n",
      "predicted number: 27\n",
      "cleaned number: 27\n",
      "9 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/ikmdSHwbjcepuGDn-figma_ss.png\n",
      "predicted number: 57\n",
      "cleaned number: 55\n",
      "10 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/AVsuP7mUiqLsXou7-unsplash_ss.png\n",
      "predicted number: 43\n",
      "cleaned number: 43\n",
      "11 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/4EYjCc2VRDXaDtDD-tds_ss.png\n",
      "predicted number: 25\n",
      "cleaned number: 25\n",
      "12 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/1esTNPnI4jN3GDsi-vox_ss.png\n",
      "predicted number: 20\n",
      "cleaned number: 20\n",
      "13 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/6dbh8UHwRgeWBCjT-markmonitor_ss.png\n",
      "predicted number: 4\n",
      "cleaned number: 4\n",
      "14 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/DjbJfJHtRs2SSbgx-cambridge_ss.png\n",
      "predicted number: 23\n",
      "cleaned number: 21\n",
      "15 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/gRc956aWXeks0zPE-statista_ss.png\n",
      "predicted number: 38\n",
      "cleaned number: 37\n",
      "16 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/SY3RMZXPRmDIAtq0-hotstar_ss.png\n",
      "predicted number: 2\n",
      "cleaned number: 2\n",
      "17 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/UyS4jfXqCi2jDFkQ-vk_ss.png\n",
      "predicted number: 20\n",
      "cleaned number: 19\n",
      "18 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/ylKSUzLu8IT6bVnm-media_ss.png\n",
      "predicted number: 29\n",
      "cleaned number: 29\n",
      "19 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/oIPNm3oBV7CwWQMa-tiktokv_ss.png\n",
      "predicted number: 33\n",
      "cleaned number: 33\n",
      "20 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/BWVn6Dew9owG4mj4-braze_ss.png\n",
      "predicted number: 35\n",
      "cleaned number: 35\n",
      "21 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/m2LxnmU8H9JpX4QZ-eventbrite_ss.png\n",
      "predicted number: 40\n",
      "cleaned number: 40\n",
      "22 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/Pp45gTKir7E7RcE9-ultradns_ss.png\n",
      "predicted number: 24\n",
      "cleaned number: 23\n",
      "23 /mnt/nis_lab_research/data/coco_files/raw/shah_b1_539_21/images/yUJn5nAijdtgIGM2-facebook_ss.png\n"
     ]
    }
   ],
   "source": [
    "master_dict = []\n",
    "\n",
    "for i, img_path in enumerate(img_path_list):\n",
    "    # Creating master dictionary of detected elements\n",
    "    img = cv2.imread(img_path)\n",
    "    outputs = obj_det_pred(img)\n",
    "    \n",
    "    print(i, img_path)\n",
    "    \n",
    "    data_dict = createDataDict(img_path, outputs)\n",
    "    bbox_list = [ann[\"bbox\"] for ann in data_dict[\"annotations\"]]\n",
    "    elem_img_list = process_image(data_dict[\"file_name\"], bbox_list, padding, bg_color, border)\n",
    "    \n",
    "    pred_ids = []\n",
    "    pred_classes = []\n",
    "    remove_list = []\n",
    "    \n",
    "    for j, img in enumerate(elem_img_list):\n",
    "        \n",
    "        img_t = transform(img.convert('RGB')).unsqueeze(0).to('cuda')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = classifier(img_t)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        pred_class_id = str(predicted.item() + 1)\n",
    "        pred_class_name = cats[pred_class_id]\n",
    "        \n",
    "        if remove_neg and pred_class_id == neg_class_id:\n",
    "            remove_list.append(j)\n",
    "\n",
    "        pred_ids.append(pred_class_id)\n",
    "        pred_classes.append(pred_classes)\n",
    "        data_dict[\"annotations\"][j][\"category_id\"] = int(pred_class_id)\n",
    "        \n",
    "    print(\"predicted number:\", len(data_dict[\"annotations\"]))\n",
    "    \n",
    "    if remove_neg and remove_list:\n",
    "         for ind in sorted(remove_list, reverse=True):\n",
    "            data_dict[\"annotations\"].pop(ind)\n",
    "            bbox_list.pop(ind)\n",
    "            pred_ids.pop(ind)\n",
    "            pred_classes.pop(ind)\n",
    "            \n",
    "    print(\"cleaned number:\", len(data_dict[\"annotations\"]))\n",
    "        \n",
    "    vis_outpath = os.path.join(vis_out_dir, os.path.basename(img_path))\n",
    "    draw_bounding_boxes(img_path, bbox_list, pred_ids, vis_outpath)\n",
    "    master_dict.append(data_dict)\n",
    "    \n",
    "res_outpath = os.path.join(res_out_dir, \"results.json\")\n",
    "print(\"writing out results to\", res_outpath)\n",
    "with open(res_outpath, 'w+') as f:\n",
    "    json.dump(master_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "int_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
